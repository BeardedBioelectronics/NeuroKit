
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Complexity &#8212; NeuroKit2 0.1.8 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/icon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Studies" href="../studies/index.html" />
    <link rel="prev" title="PPG" href="functions_ppg.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/neurokit.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Menu
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../authors.html">
   Authors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cite_us.html">
   Cite us
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../resources/index.html">
   Resources
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../resources/learn_python.html">
     Learn Python in 10 minutes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../resources/contributing.html">
     Contributing guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../resources/recording.html">
     Recording good quality signals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../resources/resources.html">
     Additional Resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Functions
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="functions_data.html">
     Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="functions_ecg.html">
     ECG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="functions_rsp.html">
     RSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="functions_hrv.html">
     HRV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="functions_ppg.html">
     PPG
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Complexity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../studies/index.html">
   Studies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/erp_gam.html">
     An GAM-based Approach to EEG/ERP Analysis using Python and R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/ecg_benchmark.html">
     Benchmarking of ECG Preprocessing Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/eog_blinktemplate.html">
     Blink Template Estimation for Electrooculography (EOG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/complexity_benchmark.html">
     Measuring Chaos: Empirical Relationship between Complexity Indices
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/neuropsychology/NeuroKit">
   Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neuropsychology/NeuroKit"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neuropsychology/NeuroKit/issues/new?title=Issue%20on%20page%20%2Ffunctions/functions_complexity.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neuropsychology/NeuroKit/edit/dev/docs_wip/functions/functions_complexity.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/functions/functions_complexity.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main">
   Main
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     <em>
      complexity()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters-choice">
   Parameters Choice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-delay">
     <em>
      complexity_delay()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-dimension">
     <em>
      complexity_dimension()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-tolerance">
     <em>
      complexity_tolerance()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-k">
     <em>
      complexity_k()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fractal-dimension">
   Fractal Dimension
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-katz">
     <em>
      fractal_katz()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-petrosian">
     <em>
      fractal_petrosian()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-sevcik">
     <em>
      fractal_sevcik()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-nld">
     <em>
      fractal_nld()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-psdslope">
     <em>
      fractal_psdslope()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-higuchi">
     <em>
      fractal_higuchi()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-correlation">
     <em>
      fractal_correlation()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entropy">
   Entropy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-shannon">
     <em>
      entropy_shannon()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-differential">
     <em>
      entropy_differential()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-tsallis">
     <em>
      entropy_tsallis()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-renyi">
     <em>
      entropy_renyi()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-cumulativeresidual">
     <em>
      entropy_cumulativeresidual()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-svd">
     <em>
      entropy_svd()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-spectral">
     <em>
      entropy_spectral()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-phase">
     <em>
      entropy_phase()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-grid">
     <em>
      entropy_grid()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-attention">
     <em>
      entropy_attention()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-increment">
     <em>
      entropy_increment()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-slope">
     <em>
      entropy_slope()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-symbolicdynamic">
     <em>
      entropy_symbolicdynamic()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-dispersion">
     <em>
      entropy_dispersion()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-ofentropy">
     <em>
      entropy_ofentropy()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-approximate">
     <em>
      entropy_approximate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-sample">
     <em>
      entropy_sample()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-permutation">
     <em>
      entropy_permutation()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-bubble">
     <em>
      entropy_bubble()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-range">
     <em>
      entropy_range()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-fuzzy">
     <em>
      entropy_fuzzy()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-multiscale">
     <em>
      entropy_multiscale()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-hierarchical">
     <em>
      entropy_hierarchical()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other">
   Other
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fisher-information">
     <em>
      fisher_information()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-hjorth">
     <em>
      complexity_hjorth()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-lempelziv">
     <em>
      complexity_lempelziv()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-relativeroughness">
     <em>
      complexity_relativeroughness()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-hurst">
     <em>
      fractal_hurst()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-lyapunov">
     <em>
      complexity_lyapunov()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-rqa">
     <em>
      complexity_rqa()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-mandelbrot">
     <em>
      fractal_mandelbrot()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-simulate">
     <em>
      complexity_simulate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-attractor">
     <em>
      complexity_attractor()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-symbolize">
     <em>
      complexity_symbolize
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-coarsegraining">
     <em>
      complexity_coarsegraining()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-ordinalpatterns">
     <em>
      complexity_ordinalpatterns()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrence-matrix">
     <em>
      recurrence_matrix()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-chains">
   Markov Chains
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transition-matrix">
     <em>
      transition_matrix()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-simulate">
     <em>
      markov_simulate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-random">
     <em>
      markov_test_random()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-symmetry">
     <em>
      markov_test_symmetry()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-homogeneity">
     <em>
      markov_test_homogeneity()
     </em>
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Complexity</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main">
   Main
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     <em>
      complexity()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters-choice">
   Parameters Choice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-delay">
     <em>
      complexity_delay()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-dimension">
     <em>
      complexity_dimension()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-tolerance">
     <em>
      complexity_tolerance()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-k">
     <em>
      complexity_k()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fractal-dimension">
   Fractal Dimension
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-katz">
     <em>
      fractal_katz()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-petrosian">
     <em>
      fractal_petrosian()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-sevcik">
     <em>
      fractal_sevcik()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-nld">
     <em>
      fractal_nld()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-psdslope">
     <em>
      fractal_psdslope()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-higuchi">
     <em>
      fractal_higuchi()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-correlation">
     <em>
      fractal_correlation()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entropy">
   Entropy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-shannon">
     <em>
      entropy_shannon()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-differential">
     <em>
      entropy_differential()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-tsallis">
     <em>
      entropy_tsallis()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-renyi">
     <em>
      entropy_renyi()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-cumulativeresidual">
     <em>
      entropy_cumulativeresidual()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-svd">
     <em>
      entropy_svd()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-spectral">
     <em>
      entropy_spectral()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-phase">
     <em>
      entropy_phase()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-grid">
     <em>
      entropy_grid()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-attention">
     <em>
      entropy_attention()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-increment">
     <em>
      entropy_increment()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-slope">
     <em>
      entropy_slope()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-symbolicdynamic">
     <em>
      entropy_symbolicdynamic()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-dispersion">
     <em>
      entropy_dispersion()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-ofentropy">
     <em>
      entropy_ofentropy()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-approximate">
     <em>
      entropy_approximate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-sample">
     <em>
      entropy_sample()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-permutation">
     <em>
      entropy_permutation()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-bubble">
     <em>
      entropy_bubble()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-range">
     <em>
      entropy_range()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-fuzzy">
     <em>
      entropy_fuzzy()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-multiscale">
     <em>
      entropy_multiscale()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entropy-hierarchical">
     <em>
      entropy_hierarchical()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other">
   Other
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fisher-information">
     <em>
      fisher_information()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-hjorth">
     <em>
      complexity_hjorth()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-lempelziv">
     <em>
      complexity_lempelziv()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-relativeroughness">
     <em>
      complexity_relativeroughness()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-hurst">
     <em>
      fractal_hurst()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-lyapunov">
     <em>
      complexity_lyapunov()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-rqa">
     <em>
      complexity_rqa()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fractal-mandelbrot">
     <em>
      fractal_mandelbrot()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-simulate">
     <em>
      complexity_simulate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-attractor">
     <em>
      complexity_attractor()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-symbolize">
     <em>
      complexity_symbolize
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-coarsegraining">
     <em>
      complexity_coarsegraining()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity-ordinalpatterns">
     <em>
      complexity_ordinalpatterns()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrence-matrix">
     <em>
      recurrence_matrix()
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-chains">
   Markov Chains
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transition-matrix">
     <em>
      transition_matrix()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-simulate">
     <em>
      markov_simulate()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-random">
     <em>
      markov_test_random()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-symmetry">
     <em>
      markov_test_symmetry()
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-test-homogeneity">
     <em>
      markov_test_homogeneity()
     </em>
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="complexity">
<h1>Complexity<a class="headerlink" href="#complexity" title="Permalink to this headline">#</a></h1>
<section id="main">
<h2>Main<a class="headerlink" href="#main" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3><em>complexity()</em><a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity">
<span class="sig-name descname"><span class="pre">complexity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['fast',</span> <span class="pre">'medium']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Automated Complexity and Chaos Analysis</strong></p>
<p>This function can be used to compute a large number of complexity metrics and features. For more
control, you can run each function separately. Note that it does not include Recurrence
Quantification Analysis (RQA, <code class="docutils literal notranslate"><span class="pre">nk.complexity_rqa()</span></code>) which currently requires an additional
dependency.</p>
<p>The categorization by “computation time” is based on our preliminary <a class="reference external" href="https://neurokit2.readthedocs.io/en/latest/studies/complexity_benchmark.html">benchmarking study</a> results:</p>
<figure class="align-default">
<a class="reference external image-reference" href="https://neurokit2.readthedocs.io/en/latest/studies/complexity_benchmark.html"><img alt="Complexity Benchmark (Makowski)." src="../_images/unnamed-chunk-3-1.png" /></a>
</figure>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>which</strong> (<em>list</em>) – What metrics to compute, based on their computation time. Can be <code class="docutils literal notranslate"><span class="pre">&quot;fast&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;medium&quot;</span></code>,
or <code class="docutils literal notranslate"><span class="pre">&quot;slow&quot;</span></code>.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A dataframe with one row containing the results for each metric as columns.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_permutation</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_differential" title="neurokit2.complexity.entropy_differential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_differential</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_svd" title="neurokit2.complexity.entropy_svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_svd</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fractal_katz" title="neurokit2.complexity.fractal_katz"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_katz</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fractal_sevcik" title="neurokit2.complexity.fractal_sevcik"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_sevcik</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fisher_information" title="neurokit2.complexity.fisher_information"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fisher_information</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_hjorth" title="neurokit2.complexity.complexity_hjorth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_hjorth</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_rqa" title="neurokit2.complexity.complexity_rqa"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_rqa</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><strong>Example 1</strong>: Compute fast and medium-fast complexity metrics</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a signal of 3 seconds</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="go"># Fast metrics</span>
<span class="gp">In [3]: </span><span class="n">df</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">which</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fast&quot;</span><span class="p">,</span> <span class="s2">&quot;medium&quot;</span><span class="p">])</span>

<span class="gp">In [4]: </span><span class="n">df</span>
<span class="gh">Out[4]: </span><span class="go"></span>
<span class="go">       ApEn      CREn    DiffEn  ...     ShanEn      SpEn     WPEn</span>
<span class="go">0  0.162527  0.628836  0.303891  ...  11.289246  0.094806  0.98896</span>

<span class="go">[1 rows x 23 columns]</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Example 2</strong>: Compute slow complexity metrics</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Slow, with specific parameters for Higuchi and MFDFA</span>
<span class="gp">In [5]: </span><span class="n">df</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">which</span> <span class="o">=</span> <span class="s2">&quot;slow&quot;</span><span class="p">,</span> <span class="n">k_max</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="gp">In [6]: </span><span class="n">df</span>
<span class="gh">Out[6]: </span><span class="go"></span>
<span class="go">        CD       DFA   FuzzyEn  ...  MFDFA_ExpRange    RCMSEn   RangeEn</span>
<span class="go">0  0.83216  1.389359  0.128788  ...        0.348173  0.706035  0.188523</span>

<span class="go">[1 rows x 13 columns]</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Example 3</strong>: Compute complexity over time</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [8]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [9]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Create dynamically varying noise</span>
<span class="gp">In [10]: </span><span class="n">amount_noise</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">amount_noise</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">amount_noise</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>

<span class="gp">In [12]: </span><span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">amount_noise</span><span class="p">))</span> <span class="o">*</span> <span class="n">amount_noise</span>

<span class="go"># Add to simple signal</span>
<span class="gp">In [13]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">+</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [14]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">sampling_rate</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity1.png"><img alt="../_images/p_complexity1.png" src="../_images/p_complexity1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Create function-wrappers that only return the index value</span>
<span class="gp">In [15]: </span><span class="n">pfd</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_petrosian</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="gp">In [16]: </span><span class="n">kfd</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_katz</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="gp">In [17]: </span><span class="n">sfd</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_sevcik</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="gp">In [18]: </span><span class="n">svden</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_svd</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="gp">In [19]: </span><span class="n">fisher</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">nk</span><span class="o">.</span><span class="n">fisher_information</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># FI is anticorrelated with complexity</span>

<span class="go"># Use them in a rolling window</span>
<span class="gp">In [20]: </span><span class="n">rolling_kfd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">kfd</span><span class="p">)</span>

<span class="gp">In [21]: </span><span class="n">rolling_pfd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pfd</span><span class="p">)</span>

<span class="gp">In [22]: </span><span class="n">rolling_sfd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sfd</span><span class="p">)</span>

<span class="gp">In [23]: </span><span class="n">rolling_svden</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">svden</span><span class="p">)</span>

<span class="gp">In [24]: </span><span class="n">rolling_fisher</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fisher</span><span class="p">)</span>

<span class="gp">In [25]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">([</span><span class="n">signal</span><span class="p">,</span>
<span class="gp">   ....: </span>                <span class="n">rolling_kfd</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="gp">   ....: </span>                <span class="n">rolling_pfd</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="gp">   ....: </span>                <span class="n">rolling_sfd</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="gp">   ....: </span>                <span class="n">rolling_svden</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="gp">   ....: </span>                <span class="n">rolling_fisher</span><span class="p">],</span>
<span class="gp">   ....: </span>                <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Signal&quot;</span><span class="p">,</span>
<span class="gp">   ....: </span>                         <span class="s2">&quot;Petrosian Fractal Dimension&quot;</span><span class="p">,</span>
<span class="gp">   ....: </span>                         <span class="s2">&quot;Katz Fractal Dimension&quot;</span><span class="p">,</span>
<span class="gp">   ....: </span>                         <span class="s2">&quot;Sevcik Fractal Dimension&quot;</span><span class="p">,</span>
<span class="gp">   ....: </span>                         <span class="s2">&quot;SVD Entropy&quot;</span><span class="p">,</span>
<span class="gp">   ....: </span>                         <span class="s2">&quot;Fisher Information&quot;</span><span class="p">],</span>
<span class="gp">   ....: </span>               <span class="n">sampling_rate</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
<span class="gp">   ....: </span>               <span class="n">standardize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">   ....: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity2.png"><img alt="../_images/p_complexity2.png" src="../_images/p_complexity2.png" style="width: 640.0px; height: 480.0px;" /></a>
</dd></dl>

</section>
</section>
<section id="parameters-choice">
<h2>Parameters Choice<a class="headerlink" href="#parameters-choice" title="Permalink to this headline">#</a></h2>
<section id="complexity-delay">
<h3><em>complexity_delay()</em><a class="headerlink" href="#complexity-delay" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_delay">
<span class="sig-name descname"><span class="pre">complexity_delay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fraser1986'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_delay" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Automated selection of the optimal Delay (Tau)</strong></p>
<p>The time delay (Tau <span class="math notranslate nohighlight">\(\tau\)</span>, also referred to as <em>Lag</em>) is one of the two critical
parameters (the other being the <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">Dimension</span></code></a> <em>m</em>) involved in the
construction of the time-delay embedding of a signal. It corresponds to the delay in samples
between the original signal and its delayed version(s). In other words, how many samples do we
consider between a given state of the signal and its closest past state.</p>
<p>When <span class="math notranslate nohighlight">\(\tau\)</span> is smaller than the optimal theoretical value, consecutive coordinates of the
system’s state are correlated and the attractor is not sufficiently unfolded. Conversely, when
<span class="math notranslate nohighlight">\(\tau\)</span> is larger than it should be, successive coordinates are almost independent,
resulting in an uncorrelated and unstructured cloud of points.</p>
<p>Several authors suggested different methods to guide the choice of the delay:</p>
<ul class="simple">
<li><p><strong>Fraser and Swinney (1986)</strong> suggest using the first local minimum of the mutual information
between the delayed and non-delayed time series, effectively identifying a value of Tau for
which they share the least information.</p></li>
<li><p><strong>Theiler (1990)</strong> suggested to select Tau where the autocorrelation between the signal and
its lagged version at Tau first crosses the value <span class="math notranslate nohighlight">\(1/e\)</span>.</p></li>
<li><p><strong>Casdagli (1991)</strong> suggests instead taking the first zero-crossing of the autocorrelation.</p></li>
<li><p><strong>Rosenstein (1993)</strong> suggests to approximate the point where the autocorrelation function
drops to <span class="math notranslate nohighlight">\((1 - 1/e)\)</span> of its maximum value.</p></li>
<li><p><strong>Rosenstein (1994)</strong> suggests to the point close to 40% of the slope of the average
displacement from the diagonal (ADFD).</p></li>
<li><p><strong>Kim (1999)</strong> suggests estimating Tau using the correlation integral, called the C-C method,
which has shown to agree with those obtained using the Mutual Information. This method
makes use of a statistic within the reconstructed phase space, rather than analyzing the
temporal evolution of the time series. However, computation times are significantly long for
this method due to the need to compare every unique pair of pairwise vectors within the
embedded signal per delay.</p></li>
<li><p><strong>Gautama (2003)</strong> mentions that in practice, it is common to have a fixed time lag and to
adjust the embedding dimension accordingly. As this can lead to large <em>m</em> values (and thus to
embedded data of a large size) and thus, slow processing, they describe an optimisation
method to jointly determine <em>m</em> and <span class="math notranslate nohighlight">\(\tau\)</span> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_optimize()</span></code>).</p></li>
<li><p><strong>Lyle (2021)</strong> describes the “Symmetric Projection Attractor Reconstruction” (SPAR), where
<span class="math notranslate nohighlight">\(1/3\)</span> of the the dominant frequency (i.e., of the length of the average “cycle”) can be
a suitable value for approximately periodic data, and makes the attractor sensitive to
morphological changes. See also <a class="reference external" href="https://youtu.be/GGrOJtcTcHA?t=730">Aston’s talk</a>. This
method is also the fastest but might not be suitable for aperiodic signals.
The <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> argument (default to <code class="docutils literal notranslate"><span class="pre">&quot;fft&quot;</span></code>) and will be passed as the <code class="docutils literal notranslate"><span class="pre">method</span></code>
argument of  <code class="docutils literal notranslate"><span class="pre">signal_psd()</span></code>.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay_max</strong> (<em>int</em>) – The maximum time delay (Tau or lag) to test.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – The method that defines what to compute for each tested value of Tau. Can be one of
<code class="docutils literal notranslate"><span class="pre">'fraser1986'</span></code>, <code class="docutils literal notranslate"><span class="pre">'theiler1990'</span></code>, <code class="docutils literal notranslate"><span class="pre">'casdagli1991'</span></code>, <code class="docutils literal notranslate"><span class="pre">'rosenstein1993'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'rosenstein1994'</span></code>, <code class="docutils literal notranslate"><span class="pre">'kim1999'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'lyle2021'</span></code>.</p></li>
<li><p><strong>algorithm</strong> (<em>str</em>) – The method used to find the optimal value of Tau given the values computed by the method.
If <cite>None</cite> (default), will select the algorithm according to the method. Modify only if you
know what you are doing.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If true, will plot the metric values for each value of tau.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments to be passed for C-C method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>delay</strong> (<em>int</em>) – Optimal time delay.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute optimal time-delay embedding.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity" title="neurokit2.complexity.complexity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embedding</span></code>, <a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_tolerance</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><strong>Example 1</strong>: Comparison of different methods for estimating the optimal delay of an simple
artificial signal.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay1.png"><img alt="../_images/p_complexity_delay1.png" src="../_images/p_complexity_delay1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;fraser1986&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay2.png"><img alt="../_images/p_complexity_delay2.png" src="../_images/p_complexity_delay2.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;theiler1990&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay3.png"><img alt="../_images/p_complexity_delay3.png" src="../_images/p_complexity_delay3.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;casdagli1991&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay4.png"><img alt="../_images/p_complexity_delay4.png" src="../_images/p_complexity_delay4.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;rosenstein1993&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay5.png"><img alt="../_images/p_complexity_delay5.png" src="../_images/p_complexity_delay5.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [8]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;rosenstein1994&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay6.png"><img alt="../_images/p_complexity_delay6.png" src="../_images/p_complexity_delay6.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">   ...: </span>                                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lyle2021&quot;</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay7.png"><img alt="../_images/p_complexity_delay7.png" src="../_images/p_complexity_delay7.png" style="width: 640.0px; height: 480.0px;" /></a>
<ul class="simple">
<li><p><strong>Example 2</strong>: Using a realistic signal.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [10]: </span><span class="n">ecg</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">ecg_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">60</span><span class="o">*</span><span class="mi">6</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">ecg_rate</span><span class="p">(</span><span class="n">nk</span><span class="o">.</span><span class="n">ecg_peaks</span><span class="p">(</span><span class="n">ecg</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">),</span>
<span class="gp">   ....: </span>                     <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<span class="gp">   ....: </span>                     <span class="n">desired_length</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ecg</span><span class="p">))</span>
<span class="gp">   ....: </span>

<span class="gp">In [12]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay8.png"><img alt="../_images/p_complexity_delay8.png" src="../_images/p_complexity_delay8.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [13]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_delay9.png"><img alt="../_images/p_complexity_delay9.png" src="../_images/p_complexity_delay9.png" style="width: 640.0px; height: 480.0px;" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Lyle, J. V., Nandi, M., &amp; Aston, P. J. (2021). Symmetric Projection Attractor Reconstruction:
Sex Differences in the ECG. Frontiers in cardiovascular medicine, 1034.</p></li>
<li><p>Gautama, T., Mandic, D. P., &amp; Van Hulle, M. M. (2003, April). A differential entropy based
method for determining the optimal embedding parameters of a signal. In 2003 IEEE
International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.
(ICASSP’03). (Vol. 6, pp. VI-29). IEEE.</p></li>
<li><p>Camplani, M., &amp; Cannas, B. (2009). The role of the embedding dimension and time delay in time
series forecasting. IFAC Proceedings Volumes, 42(7), 316-320.</p></li>
<li><p>Rosenstein, M. T., Collins, J. J., &amp; De Luca, C. J. (1993). A practical method for calculating
largest Lyapunov exponents from small data sets. Physica D: Nonlinear Phenomena, 65(1-2),
117-134.</p></li>
<li><p>Rosenstein, M. T., Collins, J. J., &amp; De Luca, C. J. (1994). Reconstruction expansion as a
geometry-based framework for choosing proper delay times. Physica-Section D, 73(1), 82-98.</p></li>
<li><p>Kim, H., Eykholt, R., &amp; Salas, J. D. (1999). Nonlinear dynamics, delay times, and embedding
windows. Physica D: Nonlinear Phenomena, 127(1-2), 48-60.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-dimension">
<h3><em>complexity_dimension()</em><a class="headerlink" href="#complexity-dimension" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_dimension">
<span class="sig-name descname"><span class="pre">complexity_dimension</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'afnn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_dimension" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Automated selection of the optimal Embedding Dimension (m)</strong></p>
<p>The Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>) is the second
critical parameter (the first being the <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">delay</span></code></a> <span class="math notranslate nohighlight">\(\tau\)</span>)
involved in the construction of the time-delay embedding of a signal. It corresponds to the
number of delayed states (versions of the signals lagged by <span class="math notranslate nohighlight">\(\tau\)</span>) that we include in
the embedding.</p>
<p>Though one can commonly find values of 2 or 3 used in practice, several authors suggested
different numerical methods to guide the choice of <em>m</em>:</p>
<ul class="simple">
<li><p><strong>Correlation Dimension</strong> (CD): One of the earliest method to estimate the optimal <em>m</em>
was to calculate the <a class="reference internal" href="#neurokit2.complexity.fractal_correlation" title="neurokit2.complexity.fractal_correlation"><code class="xref py py-func docutils literal notranslate"><span class="pre">correlation</span> <span class="pre">dimension</span></code></a> for embeddings of
various sizes and look for a saturation (i.e., a plateau) in its value as the embedding
dimension increases. One of the limitation is that a saturation will also occur when there is
not enough data to adequately fill the high-dimensional space (note that, in general, having
such large embeddings that it significantly shortens the length of the signal is not
recommended).</p></li>
<li><p><strong>FNN</strong> (False Nearest Neighbour): The method, introduced by Kennel et al. (1992), is based
on the assumption that two points that are near to each other in the sufficient embedding
dimension should remain close as the dimension increases. The algorithm checks the neighbours
in increasing embedding dimensions until it finds only a negligible number of false
neighbours when going from dimension <span class="math notranslate nohighlight">\(m\)</span> to <span class="math notranslate nohighlight">\(m+1\)</span>. This corresponds to the lowest
embedding dimension, which is presumed to give an unfolded space-state reconstruction. This
method can fail in noisy signals due to the futile attempt of unfolding the noise (and in
purely random signals, the amount of false neighbors does not substantially drops as <em>m</em>
increases).</p></li>
<li><p><strong>AFN</strong> (Average False Neighbors): This modification by Cao (1997) of the FNN method
addresses one of its main drawback, the need for a heuristic choice for the tolerance
thresholds <code class="docutils literal notranslate"><span class="pre">R</span></code>. It uses the maximal Euclidian distance to represent nearest neighbors, and
averages all ratios of the distance in <span class="math notranslate nohighlight">\(m+1\)</span> to <span class="math notranslate nohighlight">\(m\)</span> dimension and defines E1 as a
parameter. The optimal dimension corresponds to when E1(d) stops changing (reaches a plateau).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted Tau <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as Lag) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to choose the optimal value for this parameter.</p></li>
<li><p><strong>dimension_max</strong> (<em>int</em>) – The maximum embedding dimension to test.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Can be <code class="docutils literal notranslate"><span class="pre">&quot;afn&quot;</span></code> (Average False Neighbor), <code class="docutils literal notranslate"><span class="pre">&quot;fnn&quot;</span></code> (False Nearest Neighbour), or <code class="docutils literal notranslate"><span class="pre">&quot;cd&quot;</span></code>
(Correlation Dimension).</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualize the result.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments, such as <code class="docutils literal notranslate"><span class="pre">R=10.0</span></code> or <code class="docutils literal notranslate"><span class="pre">A=2.0</span></code> (relative and absolute tolerance, only for
‘fnn’ method).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted ‘Tau’ <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as ‘lag’) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to choose the optimal value for this parameter.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute the optimal dimension.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity" title="neurokit2.complexity.complexity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_tolerance</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="go"># Find optimal delay</span>
<span class="gp">In [3]: </span><span class="n">delay</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_delay</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay_max</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="go"># Find optimal dimension</span>
<span class="gp">In [4]: </span><span class="n">optimal_dimension</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_dimension</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">dimension_max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">method</span><span class="o">=</span><span class="s1">&#39;afnn&#39;</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_dimension1.png"><img alt="../_images/p_complexity_dimension1.png" src="../_images/p_complexity_dimension1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">optimal_dimension</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_dimension</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">dimension_max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">method</span><span class="o">=</span><span class="s1">&#39;fnn&#39;</span><span class="p">,</span>
<span class="gp">   ...: </span>                                                  <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_dimension2.png"><img alt="../_images/p_complexity_dimension2.png" src="../_images/p_complexity_dimension2.png" style="width: 640.0px; height: 480.0px;" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Kennel, M. B., Brown, R., &amp; Abarbanel, H. D. (1992). Determining embedding dimension for
phase-space reconstruction using a geometrical construction. Physical review A, 45(6), 3403.</p></li>
<li><p>Cao, L. (1997). Practical method for determining the minimum embedding dimension of a scalar
time series. Physica D: Nonlinear Phenomena, 110(1-2), 43-50.</p></li>
<li><p>Rhodes, C., &amp; Morari, M. (1997). The false nearest neighbors algorithm: An overview.
Computers &amp; Chemical Engineering, 21, S1149-S1154.</p></li>
<li><p>Krakovská, A., Mezeiová, K., &amp; Budáčová, H. (2015). Use of false nearest neighbours for
selecting variables and embedding parameters for state space reconstruction. Journal of
Complex Systems, 2015.</p></li>
<li><p>Gautama, T., Mandic, D. P., &amp; Van Hulle, M. M. (2003, April). A differential entropy based
method for determining the optimal embedding parameters of a signal. In 2003 IEEE
International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.
(ICASSP’03). (Vol. 6, pp. VI-29). IEEE.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-tolerance">
<h3><em>complexity_tolerance()</em><a class="headerlink" href="#complexity-tolerance" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_tolerance">
<span class="sig-name descname"><span class="pre">complexity_tolerance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'maxApEn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_tolerance" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Automated selection of tolerance (r)</strong></p>
<p>Estimate and select the optimal tolerance (<em>r</em>) parameter used by other entropy and other
complexity algorithms.</p>
<p>Many complexity algorithms are built on the notion of self-similarity and recurrence, and how
often a system revisits its past states. Considering two states as identical is straightforward
for discrete systems (e.g., a sequence of “A”, “B” and “C” states), but for continuous signals,
we cannot simply look for when the two numbers are exactly the same. Instead, we have to pick a
threshold by which to consider two points as similar.</p>
<p>The tolerance <em>r</em> is essentially this threshold value (the numerical difference between two
similar points that we “tolerate”). This parameter has a critical impact and is a major
source of inconsistencies in the literature.</p>
<p>Different methods have been described to estimate the most appropriate tolerance value:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'sd'</span></code> (as in Standard Deviation): r = 0.2 * standard deviation of the signal will be
returned.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'adjusted_sd'</span></code>: Adjusted value based on the SD and the dimension. The rationale is that
the chebyshev distance (used in various metrics) rises logarithmically with increasing
dimension. <code class="docutils literal notranslate"><span class="pre">0.5627</span> <span class="pre">*</span> <span class="pre">np.log(dimension)</span> <span class="pre">+</span> <span class="pre">1.3334</span></code> is the logarithmic trend line for the
chebyshev distance of vectors sampled from a univariate normal distribution. A constant of
<code class="docutils literal notranslate"><span class="pre">0.1164</span></code> is used so that <code class="docutils literal notranslate"><span class="pre">tolerance</span> <span class="pre">=</span> <span class="pre">0.2</span> <span class="pre">*</span> <span class="pre">SDs</span></code> for <code class="docutils literal notranslate"><span class="pre">dimension</span> <span class="pre">=</span> <span class="pre">2</span></code> (originally in
<a class="reference external" href="https://github.com/CSchoel/nolds">https://github.com/CSchoel/nolds</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'maxApEn'</span></code>: Different values of tolerance will be tested and the one where the approximate
entropy (ApEn) is maximized will be selected and returned.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'recurrence'</span></code>, the tolerance that yields a recurrence rate (see <code class="docutils literal notranslate"><span class="pre">RQA</span></code>) close to 5% will
be returned.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Can be <code class="docutils literal notranslate"><span class="pre">&quot;maxApEn&quot;</span></code> (default), <code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (or <code class="docutils literal notranslate"><span class="pre">&quot;default&quot;</span></code>), or <code class="docutils literal notranslate"><span class="pre">&quot;recurrence&quot;</span></code>.</p></li>
<li><p><strong>r_range</strong> (<em>Union[list, int]</em>) – The range of tolerance values (or the number of values) to test. Only used if <code class="docutils literal notranslate"><span class="pre">method</span></code> is
<code class="docutils literal notranslate"><span class="pre">&quot;maxApEn&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;recurrence&quot;</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code> (default), the default range will be used;
<code class="docutils literal notranslate"><span class="pre">np.linspace(0.02,</span> <span class="pre">0.8,</span> <span class="pre">r_range)</span> <span class="pre">*</span> <span class="pre">np.std(signal,</span> <span class="pre">ddof=1)</span></code> for <code class="docutils literal notranslate"><span class="pre">&quot;maxApEn&quot;</span></code>, and <code class="docutils literal notranslate"><span class="pre">np.</span>
<span class="pre">linspace(0,</span> <span class="pre">np.max(d),</span> <span class="pre">30</span> <span class="pre">+</span> <span class="pre">1)[1:]</span></code> for <code class="docutils literal notranslate"><span class="pre">&quot;recurrence&quot;</span></code>. You can set a lower number for
faster results.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Only used if <code class="docutils literal notranslate"><span class="pre">method='maxApEn'</span></code>. See <code class="docutils literal notranslate"><span class="pre">entropy_approximate()</span></code>.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Only used if <code class="docutils literal notranslate"><span class="pre">method='maxApEn'</span></code>. See <code class="docutils literal notranslate"><span class="pre">entropy_approximate()</span></code>.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If true and method is ‘maxApEn’, will plot the ApEn values for each value of r.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity" title="neurokit2.complexity.complexity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embedding</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>float</em> – The optimal tolerance value.</p></li>
<li><p><em>dict</em> – A dictionary with the values of r and the corresponding ApEn values (when method=’maxApEn’).</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><strong>Example 1</strong>: The method based on the SD of the signal is fast. The plot shows the d
distribution of the values making the signal, and the width of the arrow represents the
chosen <code class="docutils literal notranslate"><span class="pre">r</span></code> parameter.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go"># Fast method (based on the standard deviation)</span>
<span class="gp">In [3]: </span><span class="n">r</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_tolerance</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;sd&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_tolerance1.png"><img alt="../_images/p_complexity_tolerance1.png" src="../_images/p_complexity_tolerance1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">r</span>
<span class="gh">Out[4]: </span><span class="go">0.07072836242007384</span>
</pre></div>
</div>
<p>The dimension can be taken into account:
.. ipython:: python</p>
<blockquote>
<div><p># Adjusted SD
&#64;savefig p_complexity_tolerance2.png scale=100%
r, info = nk.complexity_tolerance(signal, method = “adjusted_sd”, dimension=3, show=True)
&#64;suppress
plt.close()</p>
</div></blockquote>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">r</span>
<span class="gh">Out[5]: </span><span class="go">0.07072836242007384</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Example 2</strong>: The method based on the recurrence rate will display the rates according to
different values of tolerance. The horizontal line indicates 5%.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">r</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_tolerance</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">   ...: </span>                                  <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;recurrence&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_tolerance3.png"><img alt="../_images/p_complexity_tolerance3.png" src="../_images/p_complexity_tolerance3.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="n">r</span>
<span class="gh">Out[7]: </span><span class="go">0.1259621536795725</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Example 3</strong>: The default method selects the tolerance at which <em>ApEn</em> is maximized.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Slow method</span>
<span class="gp">In [8]: </span><span class="n">r</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_tolerance</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="gp">   ...: </span>                                  <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;maxApEn&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_tolerance4.png"><img alt="../_images/p_complexity_tolerance4.png" src="../_images/p_complexity_tolerance4.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">r</span>
<span class="gh">Out[9]: </span><span class="go">0.014145672484014769</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Example 4</strong>: The tolerance values that are tested can be modified to get a more precise
estimate.</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Narrower range</span>
<span class="gp">In [10]: </span><span class="n">r</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_tolerance</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;maxApEn&#39;</span><span class="p">,</span>
<span class="gp">   ....: </span>                                  <span class="n">r_range</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.002</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ....: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_tolerance5.png"><img alt="../_images/p_complexity_tolerance5.png" src="../_images/p_complexity_tolerance5.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">r</span>
<span class="gh">Out[11]: </span><span class="go">0.6624137931034483</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Lu, S., Chen, X., Kanters, J. K., Solomon, I. C., &amp; Chon, K. H. (2008). Automatic selection of
the threshold value r for approximate entropy. IEEE Transactions on Biomedical Engineering,
55(8), 1966-1972.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-k">
<h3><em>complexity_k()</em><a class="headerlink" href="#complexity-k" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_k">
<span class="sig-name descname"><span class="pre">complexity_k</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'max'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_k" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Automated selection of k for Higuchi Fractal Dimension (HFD)</strong></p>
<p>The optimal <em>k-max</em> is computed based on the point at which HFD values plateau for a range of
<em>k-max</em> values (see Vega, 2015).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>k_max</strong> (<em>Union[int, str, list], optional</em>) – Maximum number of interval times (should be greater than or equal to 3) to be tested. If ‘max’,
it selects the maximum possible value corresponding to half the length of the signal.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualise the slope of the curve for the selected kmax value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>k</strong> (<em>float</em>) – The optimal kmax of the time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute optimal kmax.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.fractal_higuchi" title="neurokit2.complexity.fractal_higuchi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_higuchi</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">k_max</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_k</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">k_max</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_complexity_k1.png"><img alt="../_images/p_complexity_k1.png" src="../_images/p_complexity_k1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">k_max</span>
<span class="gh">Out[4]: </span><span class="go">19</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Higuchi, T. (1988). Approach to an irregular time series on the basis of the fractal theory.
Physica D: Nonlinear Phenomena, 31(2), 277-283.</p></li>
<li><p>Vega, C. F., &amp; Noel, J. (2015, June). Parameters analyzed of Higuchi’s fractal dimension for
EEG brain signals. In 2015 Signal Processing Symposium (SPSympo) (pp. 1-5). IEEE. <a class="reference external" href="https://">https://</a>
ieeexplore.ieee.org/document/7168285</p></li>
</ul>
</dd></dl>

</section>
</section>
<section id="fractal-dimension">
<h2>Fractal Dimension<a class="headerlink" href="#fractal-dimension" title="Permalink to this headline">#</a></h2>
<section id="fractal-katz">
<h3><em>fractal_katz()</em><a class="headerlink" href="#fractal-katz" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_katz">
<span class="sig-name descname"><span class="pre">fractal_katz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_katz" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Katz’s Fractal Dimension (KFD)</strong></p>
<p>Computes Katz’s Fractal Dimension (KFD). The euclidean distances between successive points in
the signal are summed and averaged, and the maximum distance between the starting point and any
other point in the sample.</p>
<p>Here, fractal dimensions range from 1.0 for straight lines, through
approximately 1.15 for random-walk waveforms, to approaching 1.5 for the most
convoluted waveforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>kfd</strong> (<em>float</em>) – Katz’s fractal dimension of the single time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information (currently empty, but returned nonetheless
for consistency with other functions).</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><strong>Step 1.</strong> Simulate different kinds of signals</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="go"># Simulate straight line</span>
<span class="gp">In [3]: </span><span class="n">straight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>

<span class="go"># Simulate random</span>
<span class="gp">In [4]: </span><span class="n">random</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;randomwalk&quot;</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">random</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">random</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="go"># Simulate simple</span>
<span class="gp">In [6]: </span><span class="n">simple</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="go"># Simulate complex</span>
<span class="gp">In [7]: </span><span class="nb">complex</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">   ...: </span>                             <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>
<span class="gp">   ...: </span>                             <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">   ...: </span>

<span class="gp">In [8]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">([</span><span class="n">straight</span><span class="p">,</span> <span class="n">random</span><span class="p">,</span> <span class="n">simple</span><span class="p">,</span> <span class="nb">complex</span><span class="p">])</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_katz.png"><img alt="../_images/p_katz.png" src="../_images/p_katz.png" style="width: 640.0px; height: 480.0px;" /></a>
<ul class="simple">
<li><p><strong>Step 2.</strong> Compute KFD for each of them</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">KFD</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_katz</span><span class="p">(</span><span class="n">straight</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">KFD</span>
<span class="gh">Out[10]: </span><span class="go">1.0</span>

<span class="gp">In [11]: </span><span class="n">KFD</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_katz</span><span class="p">(</span><span class="n">random</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">KFD</span>
<span class="gh">Out[12]: </span><span class="go">2.1583925956762395</span>

<span class="gp">In [13]: </span><span class="n">KFD</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_katz</span><span class="p">(</span><span class="n">simple</span><span class="p">)</span>

<span class="gp">In [14]: </span><span class="n">KFD</span>
<span class="gh">Out[14]: </span><span class="go">2.0418574763920256</span>

<span class="gp">In [15]: </span><span class="n">KFD</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_katz</span><span class="p">(</span><span class="nb">complex</span><span class="p">)</span>

<span class="gp">In [16]: </span><span class="n">KFD</span>
<span class="gh">Out[16]: </span><span class="go">3.8712699570456794</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Katz, M. J. (1988). Fractals and the analysis of waveforms.
Computers in Biology and Medicine, 18(3), 145-156. doi:10.1016/0010-4825(88)90041-8.</p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-petrosian">
<h3><em>fractal_petrosian()</em><a class="headerlink" href="#fractal-petrosian" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_petrosian">
<span class="sig-name descname"><span class="pre">fractal_petrosian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'C'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_petrosian" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Petrosian fractal dimension (PFD)</strong></p>
<p>Petrosian (1995) proposed a fast method to estimate the fractal dimension by converting the
signal into a binary sequence from which the fractal dimension is estimated. Several variations
of the algorithm exist (e.g., ‘A’, ‘B’, ‘C’ or ‘D’), primarily differing in the way the discrete
(symbolic) sequence is created (see func:<cite>complexity_symbolize</cite> for details). The most common
method (‘C’, by default) binarizes the signal by the sign of consecutive differences.</p>
<div class="math notranslate nohighlight">
\[\frac{log(N)}{log(N) + log(\frac{N}{N+0.4N_{\delta}})}\]</div>
<p>Most of these methods assume that the signal is periodic (without a linear trend). Linear
detrending might be useful to eliminate linear trends (see <code class="xref py py-func docutils literal notranslate"><span class="pre">signal_detrend()</span></code>).</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mutual_information</span></code>, <a class="reference internal" href="#neurokit2.complexity.entropy_svd" title="neurokit2.complexity.entropy_svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_svd</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, an
<code class="docutils literal notranslate"><span class="pre">int</span></code> indicating the number of bins, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in
cases when the binarization has already been done before). See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a>
for details.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the discrete the signal.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pfd</strong> (<em>float</em>) – The petrosian fractal dimension (PFD).</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute PFD.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>

<span class="gp">In [3]: </span><span class="n">pfd</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_petrosian</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_fractal_petrosian1.png"><img alt="../_images/p_fractal_petrosian1.png" src="../_images/p_fractal_petrosian1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">pfd</span>
<span class="gh">Out[4]: </span><span class="go">1.0012592763505226</span>

<span class="gp">In [5]: </span><span class="n">info</span>
<span class="gh">Out[5]: </span><span class="go">{&#39;Method&#39;: &#39;C&#39;}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Petrosian, A. (1995, June). Kolmogorov complexity of finite sequences and recognition of
different preictal EEG patterns. In Proceedings eighth IEEE symposium on computer-based
medical systems (pp. 212-217). IEEE.</p></li>
<li><p>Kumar, D. K., Arjunan, S. P., &amp; Aliahmad, B. (2017). Fractals: applications in biological
Signalling and image processing. CRC Press.</p></li>
<li><p>Goh, C., Hamadicharef, B., Henderson, G., &amp; Ifeachor, E. (2005, June). Comparison of fractal
dimension algorithms for the computation of EEG biomarkers for dementia. In 2nd International
Conference on Computational Intelligence in Medicine and Healthcare (CIMED2005).</p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-sevcik">
<h3><em>fractal_sevcik()</em><a class="headerlink" href="#fractal-sevcik" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_sevcik">
<span class="sig-name descname"><span class="pre">fractal_sevcik</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_sevcik" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Sevcik Fractal Dimension (SFD)</strong></p>
<p>The SFD algorithm was proposed to calculate the fractal dimension of waveforms by Sevcik
(1998). This method can be used to quickly measure the complexity and randomness of a signal.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some papers (e.g., Wang et al. 2017) suggest adding <code class="docutils literal notranslate"><span class="pre">np.log(2)</span></code> to the numerator,
but it’s unclear why, so we sticked to the original formula for now. But if you have an idea,
please let us know!</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>sfd</strong> (<em>float</em>) – The sevcik fractal dimension.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – An empty dictionary returned for consistency with the other complexity functions.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">sfd</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_sevcik</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">sfd</span>
<span class="gh">Out[4]: </span><span class="go">1.3614382329000476</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Sevcik, C. (2010). A procedure to estimate the fractal dimension of waveforms. arXiv preprint
arXiv:1003.5266.</p></li>
<li><p>Kumar, D. K., Arjunan, S. P., &amp; Aliahmad, B. (2017). Fractals: applications in biological
Signalling and image processing. CRC Press.</p></li>
<li><p>Wang, H., Li, J., Guo, L., Dou, Z., Lin, Y., &amp; Zhou, R. (2017). Fractal complexity-based
feature extraction algorithm of communication signals. Fractals, 25(04), 1740008.</p></li>
<li><p>Goh, C., Hamadicharef, B., Henderson, G., &amp; Ifeachor, E. (2005, June). Comparison of fractal
dimension algorithms for the computation of EEG biomarkers for dementia. In 2nd International
Conference on Computational Intelligence in Medicine and Healthcare (CIMED2005).</p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-nld">
<h3><em>fractal_nld()</em><a class="headerlink" href="#fractal-nld" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_nld">
<span class="sig-name descname"><span class="pre">fractal_nld</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corrected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_nld" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Fractal dimension via Normalized Length Density (NLDFD)</strong></p>
<p>NLDFD is a very basic index corresponding to the average of the absolute consecutive
differences of the (standardized) signal (<code class="docutils literal notranslate"><span class="pre">np.mean(np.abs(np.diff(std_signal)))</span></code>).
This method was developed for measuring signal complexity of very short durations (&lt; 30
samples), and can be used for instance when continuous signal FD changes (or “running” FD) are
of interest (by computing it on sliding windows, see example).</p>
<p>For methods such as Higuchi’s FD, the standard deviation of the window FD increases sharply
when the epoch becomes shorter. The NLD method results in lower standard deviation especially
for shorter epochs, though at the expense of lower accuracy in average window FD.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.fractal_higuchi" title="neurokit2.complexity.fractal_higuchi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_higuchi</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>corrected</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will rescale the output value according to the power model estimated by
Kalauzi et al. (2009) to make it more comparable with “true” FD range, as follows:
<code class="docutils literal notranslate"><span class="pre">FD</span> <span class="pre">=</span> <span class="pre">1.9079*((NLD-0.097178)^0.18383)</span></code>. Note that this can result in <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> if the
result of the difference is negative.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fd</strong> (<em>DataFrame</em>) – A dataframe containing the fractal dimension across epochs.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information (currently, but returned nonetheless for
consistency with other functions).</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p><strong>Example 1</strong>: Usage on a short signal</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a short signal with duration of 0.5s</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>

<span class="go"># Compute Fractal Dimension</span>
<span class="gp">In [3]: </span><span class="n">fd</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_nld</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">fd</span>
<span class="gh">Out[4]: </span><span class="go">0.023124767861850155</span>
</pre></div>
</div>
<p><strong>Example 2</strong>: Compute FD-NLD on non-overlapping windows</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="go"># Simulate a long signal with duration of 5s</span>
<span class="gp">In [6]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="go"># We want windows of size=100 (0.1s)</span>
<span class="gp">In [7]: </span><span class="n">n_windows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span> <span class="o">//</span> <span class="mi">100</span>  <span class="c1"># How many windows</span>

<span class="go"># Split signal into windows</span>
<span class="gp">In [8]: </span><span class="n">windows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">n_windows</span><span class="p">)</span>

<span class="go"># Compute FD-NLD on all windows</span>
<span class="gp">In [9]: </span><span class="n">nld</span> <span class="o">=</span> <span class="p">[</span><span class="n">nk</span><span class="o">.</span><span class="n">fractal_nld</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">windows</span><span class="p">]</span>

<span class="gp">In [10]: </span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">nld</span><span class="p">)</span>  <span class="c1"># Get average</span>
<span class="gh">Out[10]: </span><span class="go">0.5902548104495962</span>
</pre></div>
</div>
<p><strong>Example 3</strong>: Calculate FD-NLD on sliding windows</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Simulate a long signal with duration of 5s</span>
<span class="gp">In [11]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="go"># Add period of noise</span>
<span class="gp">In [12]: </span><span class="n">signal</span><span class="p">[</span><span class="mi">1000</span><span class="p">:</span><span class="mi">3000</span><span class="p">]</span> <span class="o">=</span> <span class="n">signal</span><span class="p">[</span><span class="mi">1000</span><span class="p">:</span><span class="mi">3000</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

<span class="go"># Create function-wrapper that only return the NLD value</span>
<span class="gp">In [13]: </span><span class="n">nld</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_nld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="go"># Use them in a rolling window of 100 samples (0.1s)</span>
<span class="gp">In [14]: </span><span class="n">rolling_nld</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nld</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">([</span><span class="n">signal</span><span class="p">,</span> <span class="n">rolling_nld</span><span class="p">],</span> <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Signal&quot;</span><span class="p">,</span> <span class="s2">&quot;FD-NLD&quot;</span><span class="p">])</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_nld1.png"><img alt="../_images/p_nld1.png" src="../_images/p_nld1.png" style="width: 640.0px; height: 480.0px;" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Kalauzi, A., Bojić, T., &amp; Rakić, L. (2009). Extracting complexity waveforms from
one-dimensional signals. Nonlinear biomedical physics, 3(1), 1-11.</p></li>
<li><p><a class="reference external" href="https://github.com/tfburns/MATLAB-functions-for-complexity-measures-of-one-dimensional-signals/blob/master/nld.m">https://github.com/tfburns/MATLAB-functions-for-complexity-measures-of-one-dimensional-signals/blob/master/nld.m</a></p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-psdslope">
<h3><em>fractal_psdslope()</em><a class="headerlink" href="#fractal-psdslope" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_psdslope">
<span class="sig-name descname"><span class="pre">fractal_psdslope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'voss1988'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_psdslope" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Fractal dimension via Power Spectral Density (PSD) slope</strong></p>
<p>Fractal exponent can be computed from Power Spectral Density slope (PSDslope) analysis in
signals characterized by a frequency power-law dependence.</p>
<p>It first transforms the time series into the frequency domain, and breaks down the signal into
sine and cosine waves of a particular amplitude that together “add-up” to represent the
original signal.
If there is a systematic relationship between the frequencies in the signal and the power of
those frequencies, this will reveal itself in log-log coordinates as a linear relationship. The
slope of the best fitting line is taken as an estimate of the fractal scaling exponent and can
be converted to an estimate of the fractal dimension.</p>
<p>A slope of 0 is consistent with white noise, and a slope of less than 0 but greater than -1,
is consistent with pink noise i.e., 1/f noise. Spectral slopes as steep as -2 indicate
fractional Brownian motion, the epitome of random walk processes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Method to estimate the fractal dimension from the slope,
can be ‘voss1988’ (default) or ‘hasselman2013’.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If True, returns the log-log plot of PSD versus frequency.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments to be passed to <code class="docutils literal notranslate"><span class="pre">signal_psd()</span></code> (such as ‘method’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>slope</strong> (<em>float</em>) – Estimate of the fractal dimension obtained from PSD slope analysis.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to perform PSD slope analysis.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal with Laplace Noise</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute the Fractal Dimension from PSD slope</span>
<span class="gp">In [3]: </span><span class="n">psdslope</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_psdslope</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_fractal_psdslope1.png"><img alt="../_images/p_fractal_psdslope1.png" src="../_images/p_fractal_psdslope1.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">psdslope</span>
<span class="gh">Out[4]: </span><span class="go">2.71789902302337</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://complexity-methods.github.io/book/power-spectral-density-psd-slope.html">https://complexity-methods.github.io/book/power-spectral-density-psd-slope.html</a></p></li>
<li><p>Hasselman, F. (2013). When the blind curve is finite: dimension estimation and model
inference based on empirical waveforms. Frontiers in Physiology, 4, 75. <a class="reference external" href="https://doi.org/10.3389/fphys.2013.00075">https://doi.org/10.3389/fphys.2013.00075</a></p></li>
<li><p>Voss, R. F. (1988). Fractals in nature: From characterization to simulation. The Science of
Fractal Images, 21-70.</p></li>
<li><p>Eke, A., Hermán, P., Kocsis, L., and Kozak, L. R. (2002). Fractal characterization of
complexity in temporal physiological signals. Physiol. Meas. 23, 1-38.</p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-higuchi">
<h3><em>fractal_higuchi()</em><a class="headerlink" href="#fractal-higuchi" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_higuchi">
<span class="sig-name descname"><span class="pre">fractal_higuchi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_higuchi" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Higuchi’s Fractal Dimension (HFD)</strong></p>
<p>Computes Higuchi’s Fractal Dimension (HFD) by reconstructing k-max number of new
data sets. For each reconstructed data set, curve length is computed and plotted
against its corresponding k value on a log-log scale. HFD equates to the slope obtained
from fitting a least-squares method.</p>
<p>Values should fall between 1 and 2. For more information about the <em>k</em> parameter selection, see
the <a class="reference internal" href="#neurokit2.complexity.complexity_k" title="neurokit2.complexity.complexity_k"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_k()</span></code></a> optimization function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>k_max</strong> (<em>str or int</em>) – Maximum number of interval times (should be greater than or equal to 2).
If <code class="docutils literal notranslate"><span class="pre">&quot;default&quot;</span></code>, the optimal k-max is estimated using <a class="reference internal" href="#neurokit2.complexity.complexity_k" title="neurokit2.complexity.complexity_k"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_k()</span></code></a>, which is slow.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualise the slope of the curve for the selected k_max value.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Currently not used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>HFD</strong> (<em>float</em>) – Higuchi’s fractal dimension of the time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute Higuchi’s fractal dimension.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_k" title="neurokit2.complexity.complexity_k"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_k</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">k_max</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span>  <span class="n">nk</span><span class="o">.</span><span class="n">complexity_k</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">k_max</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">hfd</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_higuchi</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">k_max</span><span class="o">=</span><span class="n">k_max</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/p_fractal_higuchi1.png"><img alt="../_images/p_fractal_higuchi1.png" src="../_images/p_fractal_higuchi1.png" style="width: 640.0px; height: 480.0px;" /></a>
<a class="reference internal image-reference" href="../_images/p_fractal_higuchi2.png"><img alt="../_images/p_fractal_higuchi2.png" src="../_images/p_fractal_higuchi2.png" style="width: 640.0px; height: 480.0px;" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">hfd</span>
<span class="gh">Out[5]: </span><span class="go">1.9523315727821446</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Higuchi, T. (1988). Approach to an irregular time series on the basis of the fractal theory.
Physica D: Nonlinear Phenomena, 31(2), 277-283.</p></li>
<li><p>Vega, C. F., &amp; Noel, J. (2015, June). Parameters analyzed of Higuchi’s fractal dimension for
EEG brain signals. In 2015 Signal Processing Symposium (SPSympo) (pp. 1-5). IEEE.
<a class="reference external" href="https://ieeexplore.ieee.org/document/7168285">https://ieeexplore.ieee.org/document/7168285</a></p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-correlation">
<h3><em>fractal_correlation()</em><a class="headerlink" href="#fractal-correlation" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_correlation">
<span class="sig-name descname"><span class="pre">fractal_correlation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_correlation" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Correlation Dimension (CD)</strong></p>
<p>The Correlation Dimension (CD, also denoted <em>D2</em>) is a lower bound estimate of the fractal
dimension of a signal.</p>
<p>The time series is first <code class="xref py py-func docutils literal notranslate"><span class="pre">time-delay</span> <span class="pre">embedded</span></code>, and distances
between all points in the trajectory are calculated. The “correlation sum” is the computed,
which is the proportion of pairs of points which distance is smaller than a given radius. The
final correlation dimension is then approximated by a log-log graph of correlation sum vs. a
sequence of radiuses.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">fractal_correlation()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_cd()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>radius</strong> (<em>Union[str, int, list]</em>) – The sequence of radiuses to test. If an integer is passed, will get an exponential sequence
of length <code class="docutils literal notranslate"><span class="pre">radius</span></code> ranging from 2.5% to 50% of the distance range. Methods implemented in
other packages can be used via setting <code class="docutils literal notranslate"><span class="pre">r='nolds'</span></code>, <code class="docutils literal notranslate"><span class="pre">r='Corr_Dim'</span></code> or <code class="docutils literal notranslate"><span class="pre">r='boon2008'</span></code>.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Plot of correlation dimension if True. Defaults to False.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments to be passed (not used for now).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>cd</strong> (<em>float</em>) – The Correlation Dimension (CD) of the time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute the correlation dimension.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>

<span class="gp">In [3]: </span><span class="n">cd</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_correlation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">cd</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_correlation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="s2">&quot;nolds&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">cd</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_correlation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="s1">&#39;boon2008&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_correlation1.png"><img alt="savefig/p_fractal_correlation1.png" src="savefig/p_fractal_correlation1.png" /></a>
<a class="reference internal image-reference" href="savefig/p_fractal_correlation2.png"><img alt="savefig/p_fractal_correlation2.png" src="savefig/p_fractal_correlation2.png" /></a>
<a class="reference internal image-reference" href="savefig/p_fractal_correlation3.png"><img alt="savefig/p_fractal_correlation3.png" src="savefig/p_fractal_correlation3.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Bolea, J., Laguna, P., Remartínez, J. M., Rovira, E., Navarro, A., &amp; Bailón, R. (2014).
Methodological framework for estimating the correlation dimension in HRV signals.
Computational and mathematical methods in medicine, 2014.</p></li>
<li><p>Boon, M. Y., Henry, B. I., Suttle, C. M., &amp; Dain, S. J. (2008). The correlation dimension:
A useful objective measure of the transient visual evoked potential?. Journal of vision,
8(1), 6-6.</p></li>
</ul>
</dd></dl>

</section>
</section>
<section id="entropy">
<h2>Entropy<a class="headerlink" href="#entropy" title="Permalink to this headline">#</a></h2>
<section id="entropy-shannon">
<h3><em>entropy_shannon()</em><a class="headerlink" href="#entropy-shannon" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_shannon">
<span class="sig-name descname"><span class="pre">entropy_shannon</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_shannon" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Shannon entropy (SE or ShanEn)</strong></p>
<p>Compute Shannon entropy (SE). Entropy is a measure of unpredictability of the
state, or equivalently, of its average information content. Shannon entropy (SE) is one of the
first and most basic measure of entropy and a foundational concept of information theory,
introduced by Shannon (1948) to quantify the amount of information in a variable.</p>
<div class="math notranslate nohighlight">
\[ShanEn = -\sum_{x \in \mathcal{X}} p(x) \log_2 p(x)\]</div>
<p>Shannon attempted to extend Shannon entropy in what has become known as Differential Entropy
(see :func`entropy_differential`).</p>
<p>Because Shannon entropy was meant for symbolic sequences (discrete events such as [“A”, “B”,
“B”, “A”]), it does not do well with continuous signals. One option is to binarize (i.e., cut)
the signal into a number of bins using for instance <code class="docutils literal notranslate"><span class="pre">pd.cut(signal,</span> <span class="pre">bins=100,</span> <span class="pre">labels=False)</span></code>.
This can be done automatically using the <code class="docutils literal notranslate"><span class="pre">method</span></code> argument, which will be transferred to :
func:<cite>complexity_symbolize</cite>.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_shannon()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_se()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>base</strong> (<em>float</em>) – The logarithmic base to use, defaults to <code class="docutils literal notranslate"><span class="pre">2</span></code>. Note that <code class="docutils literal notranslate"><span class="pre">scipy.stats.entropy()</span></code>
uses <code class="docutils literal notranslate"><span class="pre">np.e</span></code> as default (the natural logarithm).</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, an
<code class="docutils literal notranslate"><span class="pre">int</span></code> indicating the number of bins, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in
cases when the binarization has already been done before). See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a>
for details.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the discrete the signal.</p></li>
<li><p><strong>freq</strong> (<em>np.array</em>) – Instead of a signal, a vector of probabilities can be provided (used for instance in
<a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_permutation()</span></code></a>).</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments. Not used for now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>shanen</strong> (<em>float</em>) – The Shannon entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute Shannon entropy.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_differential" title="neurokit2.complexity.entropy_differential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_differential</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_cumulative_residual</span></code>, <a class="reference internal" href="#neurokit2.complexity.entropy_tsallis" title="neurokit2.complexity.entropy_tsallis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_tsallis</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_renyi" title="neurokit2.complexity.entropy_renyi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_renyi</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">_</span><span class="p">,</span> <span class="n">freq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">nk</span><span class="o">.</span><span class="n">entropy_shannon</span><span class="p">(</span><span class="n">freq</span><span class="o">=</span><span class="n">freq</span><span class="p">)</span>
<span class="gh">Out[4]: </span><span class="go">(1.8423709931771086, {&#39;Method&#39;: None, &#39;Base&#39;: 2})</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Simulate a Signal with Laplace Noise</span>
<span class="gp">In [5]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="go"># Compute Shannon&#39;s Entropy</span>
<span class="gp">In [6]: </span><span class="n">shanen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_shannon</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_shannon1.png"><img alt="savefig/p_entropy_shannon1.png" src="savefig/p_entropy_shannon1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="n">shanen</span>
<span class="gh">Out[7]: </span><span class="go">1.5516261099706012</span>
</pre></div>
</div>
<p>Compare with <code class="docutils literal notranslate"><span class="pre">scipy</span></code> (using the same base).</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [8]: </span><span class="kn">import</span> <span class="nn">scipy.stats</span>

<span class="go"># Make the binning ourselves</span>
<span class="gp">In [9]: </span><span class="n">binned</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">entropy</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">binned</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="gh">Out[10]: </span><span class="go">1.075505263409318</span>

<span class="gp">In [11]: </span><span class="n">shanen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_shannon</span><span class="p">(</span><span class="n">binned</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">shanen</span>
<span class="gh">Out[12]: </span><span class="go">1.0755052634093178</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Shannon, C. E. (1948). A mathematical theory of communication. The Bell system technical
journal, 27(3), 379-423.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-differential">
<h3><em>entropy_differential()</em><a class="headerlink" href="#entropy-differential" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_differential">
<span class="sig-name descname"><span class="pre">entropy_differential</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_differential" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Differential entropy (DiffEn)</strong></p>
<p>Differential entropy (DiffEn; also referred to as continuous entropy) started as an
attempt by Shannon to extend Shannon entropy. However, differential entropy presents some
issues too, such as that it can be negative even for simple distributions (such as the uniform
distribution).</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_differential()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_diffen()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other arguments passed to <code class="docutils literal notranslate"><span class="pre">scipy.stats.differential_entropy()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>diffen</strong> (<em>float</em>) – The Differential entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute Differential entropy.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_cumulative_residual</span></code></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal with Laplace Noise</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="go"># Compute Differential Entropy</span>
<span class="gp">In [3]: </span><span class="n">diffen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_differential</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">diffen</span>
<span class="gh">Out[4]: </span><span class="go">0.3771342215426443</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.differential_entropy.html">scipy.stats.differential_entropy()</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Differential_entropy">https://en.wikipedia.org/wiki/Differential_entropy</a></p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-tsallis">
<h3><em>entropy_tsallis()</em><a class="headerlink" href="#entropy-tsallis" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_tsallis">
<span class="sig-name descname"><span class="pre">entropy_tsallis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_tsallis" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Tsallis entropy (TSEn)</strong></p>
<p>Tsallis Entropy is an extension of <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a> to the case where
entropy is nonextensive. It is similarly computed from a vector of probabilities of different
states. Because it works on discrete inputs (e.g., [A, B, B, A, B]), it requires to transform
the continuous signal into a discrete one.</p>
<div class="math notranslate nohighlight">
\[TSEn = \frac{1}{q - 1} \left( 1 - \sum_{x \in \mathcal{X}} p(x)^q \right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>q</strong> (<em>float</em>) – Tsallis’s <em>q</em> parameter, sometimes referred to as the entropic-index (default to 1).</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of discretization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, an
<code class="docutils literal notranslate"><span class="pre">int</span></code> indicating the number of bins, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in
cases when the binarization has already been done before). See <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-func docutils literal notranslate"><span class="pre">fractal_petrosian()</span></code></a>
for details.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the discrete the signal.</p></li>
<li><p><strong>freq</strong> (<em>np.array</em>) – Instead of a signal, a vector of probabilities can be provided.</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments. Not used for now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>tsen</strong> (<em>float</em>) – The Tsallis entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_renyi" title="neurokit2.complexity.entropy_renyi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_renyi</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">tsen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_tsallis</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">tsen</span>
<span class="gh">Out[4]: </span><span class="go">1.5229550675313184</span>

<span class="gp">In [5]: </span><span class="n">shanen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_shannon</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">shanen</span>
<span class="gh">Out[6]: </span><span class="go">1.5229550675313184</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Tsallis, C. (2009). Introduction to nonextensive statistical mechanics: approaching a complex
world. Springer, 1(1), 2-1.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-renyi">
<h3><em>entropy_renyi()</em><a class="headerlink" href="#entropy-renyi" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_renyi">
<span class="sig-name descname"><span class="pre">entropy_renyi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_renyi" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Rényi entropy (REn or H)</strong></p>
<p>In information theory, the Rényi entropy <em>H</em> generalizes the Hartley entropy, the Shannon
entropy, the collision entropy and the min-entropy.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha = 0\)</span>: the Rényi entropy becomes what is known as the <strong>Hartley entropy</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha = 1\)</span>: the Rényi entropy becomes the <strong>:func:`Shannon entropy &lt;entropy_shannon&gt;`</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha = 2\)</span>: the Rényi entropy becomes the collision entropy, which corresponds to
the surprisal of “rolling doubles”.</p></li>
</ul>
<p>It is mathematically defined as:</p>
<div class="math notranslate nohighlight">
\[REn = \frac{1}{1-\alpha} \log_2 \left( \sum_{x \in \mathcal{X}} p(x)^\alpha \right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The <em>alpha</em> <span class="math notranslate nohighlight">\(\alpha\)</span> parameter (default to 1) for Rényi entropy.</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of discretization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, an
<code class="docutils literal notranslate"><span class="pre">int</span></code> indicating the number of bins, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in
cases when the binarization has already been done before). See <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-func docutils literal notranslate"><span class="pre">fractal_petrosian()</span></code></a>
for details.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the discrete the signal.</p></li>
<li><p><strong>freq</strong> (<em>np.array</em>) – Instead of a signal, a vector of probabilities can be provided.</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments. Not used for now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ren</strong> (<em>float</em>) – The Tsallis entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_tsallis" title="neurokit2.complexity.entropy_tsallis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_tsallis</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">tsen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_renyi</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">tsen</span>
<span class="gh">Out[4]: </span><span class="go">1.5229550675313184</span>

<span class="gp">In [5]: </span><span class="n">shanen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_shannon</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">shanen</span>
<span class="gh">Out[6]: </span><span class="go">1.5229550675313184</span>

<span class="go"># Hartley Entropy</span>
<span class="gp">In [7]: </span><span class="n">nk</span><span class="o">.</span><span class="n">entropy_renyi</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gh">Out[7]: </span><span class="go">1.6094379124341003</span>

<span class="go"># Collision Entropy</span>
<span class="gp">In [8]: </span><span class="n">nk</span><span class="o">.</span><span class="n">entropy_renyi</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gh">Out[8]: </span><span class="go">1.4500101755059984</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rényi, A. (1961, January). On measures of entropy and information. In Proceedings of the
Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1:
Contributions to the Theory of Statistics (Vol. 4, pp. 547-562). University of California
Press.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-cumulativeresidual">
<h3><em>entropy_cumulativeresidual()</em><a class="headerlink" href="#entropy-cumulativeresidual" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_cumulativeresidual">
<span class="sig-name descname"><span class="pre">entropy_cumulativeresidual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_cumulativeresidual" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Cumulative residual entropy (CREn)</strong></p>
<p>The cumulative residual entropy is an alternative to the Shannon
differential entropy with several advantageous properties, such as non-negativity. The key idea
is to use the cumulative distribution (CDF) instead of the density function in Shannon’s
entropy.</p>
<div class="math notranslate nohighlight">
\[CREn = -\int_{0}^{\infty} p(|X| &gt; x) \log_{2} p(|X| &gt; x) dx\]</div>
<p>Similarly to <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a> and <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-func docutils literal notranslate"><span class="pre">Petrosian</span> <span class="pre">fractal</span> <span class="pre">dimension</span></code></a>, different methods to transform continuous signals into discrete ones are
available. See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a> for details.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_cumulativeresidual()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_cren()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, an
<code class="docutils literal notranslate"><span class="pre">int</span></code> indicating the number of bins, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in
cases when the binarization has already been done before). See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a>
for details.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the discrete the signal.</p></li>
<li><p><strong>freq</strong> (<em>np.array</em>) – Instead of a signal, a vector of probabilities can be provided.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>CREn</strong> (<em>float</em>) – The cumulative residual entropy.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing ‘Values’ for each pair of events.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">cren</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_cumulativeresidual</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_cumulativeresidual1.png"><img alt="savefig/p_entropy_cumulativeresidual1.png" src="savefig/p_entropy_cumulativeresidual1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">cren</span>
<span class="gh">Out[4]: </span><span class="go">0.8706159142657933</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rao, M., Chen, Y., Vemuri, B. C., &amp; Wang, F. (2004). Cumulative residual entropy: a new
measure of information. IEEE transactions on Information Theory, 50(6), 1220-1228.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-svd">
<h3><em>entropy_svd()</em><a class="headerlink" href="#entropy-svd" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_svd">
<span class="sig-name descname"><span class="pre">entropy_svd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_svd" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Singular Value Decomposition (SVD) Entropy</strong></p>
<p>SVD entropy (SVDEn) can be intuitively seen as an indicator of how many eigenvectors are needed
for an adequate explanation of the dataset. In other words, it measures feature-richness: the
higher the SVD entropy, the more orthogonal vectors are required to adequately explain the
space-state. Similarly to <code class="xref py py-func docutils literal notranslate"><span class="pre">Fisher</span> <span class="pre">Information</span> <span class="pre">(FI)</span></code>, it is based on
the Singular Value Decomposition of the <code class="xref py py-func docutils literal notranslate"><span class="pre">time-delay</span> <span class="pre">embedded</span></code> signal.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">information_fisher</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embedding</span></code>, <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>svd</strong> (<em>float</em>) – The singular value decomposition (SVD).</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute SVDEn.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">svden</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_svd</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">svden</span>
<span class="gh">Out[4]: </span><span class="go">0.5091667337544503</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="entropy-spectral">
<h3><em>entropy_spectral()</em><a class="headerlink" href="#entropy-spectral" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_spectral">
<span class="sig-name descname"><span class="pre">entropy_spectral</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_spectral" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Spectral Entropy (SpEn)</strong></p>
<p>Spectral entropy (SE or SpEn) treats the signal’s normalized power distribution in the
frequency domain as a probability distribution, and calculates the Shannon entropy of it.</p>
<p>A signal with a single frequency component (i.e., pure sinusoid) produces the smallest entropy.
On the other hand, a signal with all frequency components of equal power value (white
noise) produces the greatest entropy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>c</strong> (<em>int</em>) – Number of bins of frequency.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Keyword arguments to be passed to <cite>signal_psd()</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>SpEn</strong> (<em>float</em>) – Spectral Entropy</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_wiener</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">signal_psd</span></code></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal with Laplace Noise</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="go"># Compute Spectral Entropy</span>
<span class="gp">In [3]: </span><span class="n">SpEn</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_spectral</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">SpEn</span>
<span class="gh">Out[4]: </span><span class="go">0.3669782669696597</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Crepeau, J. C., &amp; Isaacson, L. K. (1991). Spectral Entropy Measurements of Coherent
Structures in an Evolving Shear Layer. Journal of Non-Equilibrium Thermodynamics, 16(2).
doi:10.1515/jnet.1991.16.2.137</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-phase">
<h3><em>entropy_phase()</em><a class="headerlink" href="#entropy-phase" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_phase">
<span class="sig-name descname"><span class="pre">entropy_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_phase" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Phase Entropy (PhasEn)</strong></p>
<p>Phase entropy (PhasEn or PhEn) has been developed by quantifying the distribution of the signal
in accross <em>n</em> parts (a parameter also denoted <em>k</em>) of a two-dimensional phase space
referred to as a second order difference plot (SODP). It build on the concept of
<a class="reference internal" href="#neurokit2.complexity.entropy_grid" title="neurokit2.complexity.entropy_grid"><code class="xref py py-func docutils literal notranslate"><span class="pre">Grid</span> <span class="pre">Entropy</span></code></a>, that uses <a class="reference internal" href="functions_hrv.html#neurokit2.hrv.hrv_nonlinear" title="neurokit2.hrv.hrv_nonlinear"><code class="xref py py-func docutils literal notranslate"><span class="pre">Poincaré</span> <span class="pre">plot</span></code></a> as its basis.</p>
<figure class="align-default">
<a class="reference external image-reference" href="https://doi.org/10.1088/1361-6579/ab499e"><img alt="Figure from Rohila et al. (2019)." src="../_images/rohila2019.png" /></a>
</figure>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of sections that the SODP is divided into, often denoted <em>k</em>. It is a coarse
graining parameter that defines how fine the grid is. It is recommended to use even-numbered
(preferably multiples of 4) partitions for sake of symmetry.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Plot the Second Order Difference Plot (SODP).</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments, such as the logarithmic <code class="docutils literal notranslate"><span class="pre">base</span></code> to use for
<a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_shannon()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>phasen</strong> (<em>float</em>) – Phase Entropy</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute Phase Entropy</span>
<span class="gp">In [3]: </span><span class="n">phasen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_phase</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_phase1.png"><img alt="savefig/p_entropy_phase1.png" src="savefig/p_entropy_phase1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">phasen</span>
<span class="gh">Out[4]: </span><span class="go">1.1375696959060588</span>

<span class="gp">In [5]: </span><span class="n">phasen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_phase</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_phase2.png"><img alt="savefig/p_entropy_phase2.png" src="savefig/p_entropy_phase2.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rohila, A., &amp; Sharma, A. (2019). Phase entropy: A new complexity measure for heart rate
variability. Physiological Measurement, 40(10), 105006.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-grid">
<h3><em>entropy_grid()</em><a class="headerlink" href="#entropy-grid" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_grid">
<span class="sig-name descname"><span class="pre">entropy_grid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_grid" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Grid Entropy (GridEn)</strong></p>
<p>Grid Entropy (GridEn or GDEn) is defined as a gridded descriptor of a <a class="reference internal" href="functions_hrv.html#neurokit2.hrv.hrv_nonlinear" title="neurokit2.hrv.hrv_nonlinear"><code class="xref py py-func docutils literal notranslate"><span class="pre">Poincaré</span> <span class="pre">plot</span></code></a>,
which is a two-dimensional phase space diagram of a time series that plots the present sample
of a time series with respect to their delayed values. The plot is divided into <span class="math notranslate nohighlight">\(n*n\)</span>
grids, and the <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a> is computed from the probability
distribution of the number of points in each grid.</p>
<p>Yan et al. (2019) define two novel measures, namely <strong>GridEn</strong> and <strong>Gridded Distribution Rate
(GDR)</strong>, the latter being the percentage of grids containing points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of sections that the Poincaré plot is divided into. It is a coarse
graining parameter that defines how fine the grid is.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Plot the Poincaré plot.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments, such as the logarithmic <code class="docutils literal notranslate"><span class="pre">base</span></code> to use for
<a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_shannon()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>griden</strong> (<em>float</em>) – Grid Entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="functions_hrv.html#neurokit2.hrv.hrv_nonlinear" title="neurokit2.hrv.hrv_nonlinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hrv_nonlinear</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_phase" title="neurokit2.complexity.entropy_phase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_phase</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute Grid Entropy</span>
<span class="gp">In [3]: </span><span class="n">phasen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_grid</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_grid1.png"><img alt="savefig/p_entropy_grid1.png" src="savefig/p_entropy_grid1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">phasen</span>
<span class="gh">Out[4]: </span><span class="go">2.5933410185542973</span>

<span class="gp">In [5]: </span><span class="n">phasen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_grid</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_grid2.png"><img alt="savefig/p_entropy_grid2.png" src="savefig/p_entropy_grid2.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;GDR&quot;</span><span class="p">]</span>
<span class="gh">Out[6]: </span><span class="go">0.79</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Yan, C., Li, P., Liu, C., Wang, X., Yin, C., &amp; Yao, L. (2019). Novel gridded descriptors of
poincaré plot for analyzing heartbeat interval time-series. Computers in biology and
medicine, 109, 280-289.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-attention">
<h3><em>entropy_attention()</em><a class="headerlink" href="#entropy-attention" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_attention">
<span class="sig-name descname"><span class="pre">entropy_attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_attention" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Attention Entropy (AttEn)</strong></p>
<p>Yang et al. (2020) propose a conceptually new approach called <strong>Attention Entropy (AttEn)</strong>,
which pays attention only to the key observations. Instead of counting the frequency of all
observations, it analyzes the frequency distribution of the intervals between the key
observations in a time-series. The advantages of the attention entropy are that it does not
need any parameter to tune, is robust to the time-series length, and requires only linear time
to compute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>atten</strong> (<em>float</em>) – The attention entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing values of sub-entropies that are averaged to give the general
AttEn, such as <code class="docutils literal notranslate"><span class="pre">MaxMax</span></code> (entropy of local-maxima intervals), <code class="docutils literal notranslate"><span class="pre">MinMin</span></code> (entropy of
local-minima intervals), <code class="docutils literal notranslate"><span class="pre">MaxMin</span></code> (entropy of intervals between local maxima and
subsequent minima), and <code class="docutils literal notranslate"><span class="pre">MinMax</span></code> (entropy of intervals between local minima and
subsequent maxima ).</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_cumulative_residual</span></code></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="go"># Compute Attention Entropy</span>
<span class="gp">In [3]: </span><span class="n">atten</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_attention</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">atten</span>
<span class="gh">Out[4]: </span><span class="go">1.1248074824440113</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Yang, J., Choudhary, G. I., Rahardja, S., &amp; Franti, P. (2020). Classification of interbeat
interval time-series using attention entropy. IEEE Transactions on Affective Computing.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-increment">
<h3><em>entropy_increment()</em><a class="headerlink" href="#entropy-increment" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_increment">
<span class="sig-name descname"><span class="pre">entropy_increment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_increment" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Increment Entropy (IncrEn) and its Multiscale variant (MSIncrEn)</strong></p>
<p>Increment Entropy (IncrEn) quantifies the magnitudes of the variations between adjacent
elements into ranks based on a precision factor <em>q</em> and the standard deviation of the time
series. IncrEn is conceptually similar to <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation</span> <span class="pre">entropy</span></code></a> in
that it also uses the concepts of symbolic dynamics.</p>
<p>In the IncrEn calculation, two letters are used to describe the relationship between adjacent
elements in a time series. One letter represents the volatility direction, and the other
represents the magnitude of the variation between the adjacent elements.</p>
<p>The time series is reconstructed into vectors of <em>m</em> elements. Each element of each vector
represents the increment between two neighbouring elements in the original time series.
Each increment element is mapped to a word consisting of two letters (one letter represents
the volatility direction, and the other represents the magnitude of the variation between
the adjacent elements), and then, each vector is described as a symbolic (discrete) pattern.
The <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a> of the probabilities of independent patterns is
then computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>q</strong> (<em>float</em>) – The quantifying resolution <em>q</em> represents the precision of <em>IncrEn</em>, with larger values
indicating a higher precision, causing IncrEn to be more sensitive to subtle fluctuations.
The IncrEn value increases with increasing <em>q</em>, until reaching a plateau. This property can
be useful to selecting an optimal <em>q</em> value.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments, such as the logarithmic <code class="docutils literal notranslate"><span class="pre">base</span></code> to use for
<a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_shannon()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>incren</strong> (<em>float</em>) – The Increment Entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used, such as the
average entropy <code class="docutils literal notranslate"><span class="pre">AvEn</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># IncrEn</span>
<span class="gp">In [3]: </span><span class="n">incren</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_increment</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">incren</span>
<span class="gh">Out[4]: </span><span class="go">2.7527561966766747</span>

<span class="go"># Multiscale IncrEn (MSIncrEn)</span>
<span class="gp">In [5]: </span><span class="n">msincren</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSIncrEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_increment1.png"><img alt="savefig/p_entropy_increment1.png" src="savefig/p_entropy_increment1.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Liu, X., Jiang, A., Xu, N., &amp; Xue, J. (2016). Increment entropy as a measure of complexity
for time series. Entropy, 18(1), 22.</p></li>
<li><p>Liu, X., Jiang, A., Xu, N., &amp; Xue, J. (2016). Correction on Liu, X.; Jiang, A.; Xu, N.; Xue,
J. Increment Entropy as a Measure of Complexity for Time Series. Entropy 2016, 18, 22.
Entropy, 18(4), 133.</p></li>
<li><p>Liu, X., Wang, X., Zhou, X., &amp; Jiang, A. (2018). Appropriate use of the increment entropy for
electrophysiological time series. Computers in Biology and Medicine, 95, 13-23.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-slope">
<h3><em>entropy_slope()</em><a class="headerlink" href="#entropy-slope" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_slope">
<span class="sig-name descname"><span class="pre">entropy_slope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.1,</span> <span class="pre">45]</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_slope" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Slope Entropy (SlopEn)</strong></p>
<p>Slope Entropy (SlopEn) uses an alphabet of three symbols, 0, 1, and 2, with positive (+) and
negative versions (-) of the last two. Each symbol covers a range of slopes for the segment
joining two consecutive samples of the input data, and the <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a>
of the relative frequency of each pattern is computed.</p>
<figure class="align-default">
<a class="reference external image-reference" href="https://doi.org/10.3390/e21121167"><img alt="Figure from Cuesta-Frau, D. (2019)." src="../_images/cuestafrau2019.png" /></a>
</figure>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>thresholds</strong> (<em>list</em>) – Angular thresholds (called <em>levels</em>). A list of monotonically increasing  values in the
range [0, 90] degrees.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments, such as the logarithmic <code class="docutils literal notranslate"><span class="pre">base</span></code> to use for
<a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_shannon()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>slopen</strong> (<em>float</em>) – Slope Entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute Slope Entropy</span>
<span class="gp">In [3]: </span><span class="n">slopen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_slope</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">thresholds</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">45</span><span class="p">])</span>

<span class="gp">In [4]: </span><span class="n">slopen</span>
<span class="gh">Out[4]: </span><span class="go">3.784042307359139</span>

<span class="gp">In [5]: </span><span class="n">slopen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_slope</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">thresholds</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">60</span><span class="p">])</span>

<span class="gp">In [6]: </span><span class="n">slopen</span>
<span class="gh">Out[6]: </span><span class="go">5.042714672870506</span>

<span class="go"># Compute Multiscale Slope Entropy (MSSlopEn)</span>
<span class="gp">In [7]: </span><span class="n">msslopen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSSlopEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_slope1.png"><img alt="savefig/p_entropy_slope1.png" src="savefig/p_entropy_slope1.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Cuesta-Frau, D. (2019). Slope entropy: A new time series complexity estimator based on both
symbolic patterns and amplitude information. Entropy, 21(12), 1167.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-symbolicdynamic">
<h3><em>entropy_symbolicdynamic()</em><a class="headerlink" href="#entropy-symbolicdynamic" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_symbolicdynamic">
<span class="sig-name descname"><span class="pre">entropy_symbolicdynamic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MEP'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_symbolicdynamic" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Symbolic Dynamic Entropy (SyDyEn) and its Multiscale variants (MSSyDyEn)</strong></p>
<p>Symbolic Dynamic Entropy (SyDyEn) combines the merits of symbolic dynamic and information
theory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>c</strong> (<em>int</em>) – Number of symbols <em>c</em>.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;MEP&quot;</span></code> (default), <code class="docutils literal notranslate"><span class="pre">&quot;NCDF&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;uniform&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;kmeans&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;equal&quot;</span></code>, or others. See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a> for
details.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments (currently not used).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>SyDyEn</strong> (<em>float</em>) – Symbolic Dynamic Entropy (SyDyEn) of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_dispersion" title="neurokit2.complexity.entropy_dispersion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_dispersion</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute Symbolic Dynamic Entropy</span>
<span class="gp">In [3]: </span><span class="n">sydyen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_symbolicdynamic</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MEP&quot;</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">sydyen</span>
<span class="gh">Out[4]: </span><span class="go">3.683507971234752</span>

<span class="gp">In [5]: </span><span class="n">sydyen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_symbolicdynamic</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">sydyen</span>
<span class="gh">Out[6]: </span><span class="go">3.290420062892821</span>

<span class="go"># Compute Multiscale Symbolic Dynamic Entropy (MSSyDyEn)</span>
<span class="gp">In [7]: </span><span class="n">mssydyen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSSyDyEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go"># Compute Modified Multiscale Symbolic Dynamic Entropy (MMSyDyEn)</span>
<span class="gp">In [8]: </span><span class="n">mmsydyen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MMSyDyEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_symbolicdynamic1.png"><img alt="savefig/p_entropy_symbolicdynamic1.png" src="savefig/p_entropy_symbolicdynamic1.png" /></a>
<a class="reference internal image-reference" href="savefig/p_entropy_symbolicdynamic2.png"><img alt="savefig/p_entropy_symbolicdynamic2.png" src="savefig/p_entropy_symbolicdynamic2.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Li, Y., Yang, Y., Li, G., Xu, M., &amp; Huang, W. (2017). A fault diagnosis scheme for planetary
gearboxes using modified multi-scale symbolic dynamic entropy and mRMR feature selection.
Mechanical Systems and Signal Processing, 91, 295-312.</p></li>
<li><p>Rajagopalan, V., &amp; Ray, A. (2006). Symbolic time series analysis via wavelet-based
partitioning. Signal processing, 86(11), 3309-3320.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-dispersion">
<h3><em>entropy_dispersion()</em><a class="headerlink" href="#entropy-dispersion" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_dispersion">
<span class="sig-name descname"><span class="pre">entropy_dispersion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDF'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fluctuation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_dispersion" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Dispersion Entropy (DispEn)</strong></p>
<p>The Dispersion Entropy (DispEn). Also returns the Reverse Dispersion Entropy (RDEn).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>c</strong> (<em>int</em>) – Number of symbols <em>c</em>. Rostaghi (2016) recommend in practice a <em>c</em> between 4 and 8.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;NCDF&quot;</span></code> (default), <code class="docutils literal notranslate"><span class="pre">&quot;finesort&quot;</span></code>, or others. See
<a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a> for details.</p></li>
<li><p><strong>fluctuation</strong> (<em>bool</em>) – Fluctuation-based Dispersion entropy.</p></li>
<li><p><strong>rho</strong> (<em>float</em>) – Tuning parameter of “finesort”. Only when <code class="docutils literal notranslate"><span class="pre">method=&quot;finesort&quot;</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments (currently not used).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>DispEn</strong> (<em>float</em>) – Dispersion Entropy (DispEn) of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_symbolicdynamic" title="neurokit2.complexity.entropy_symbolicdynamic"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_symbolicdynamic</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Compute Dispersion Entropy (DispEn)</span>
<span class="gp">In [3]: </span><span class="n">dispen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_dispersion</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">dispen</span>
<span class="gh">Out[4]: </span><span class="go">1.4127157719605257</span>

<span class="go"># Get Reverse Dispersion Entropy (RDEn)</span>
<span class="gp">In [5]: </span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;RDEn&quot;</span><span class="p">]</span>
<span class="gh">Out[5]: </span><span class="go">0.005029496147144691</span>

<span class="go"># Fluctuation-based DispEn with &quot;finesort&quot;</span>
<span class="gp">In [6]: </span><span class="n">dispen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_dispersion</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;finesort&quot;</span><span class="p">,</span> <span class="n">fluctuation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">dispen</span>
<span class="gh">Out[7]: </span><span class="go">1.4127157719605257</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rostaghi, M., &amp; Azami, H. (2016). Dispersion entropy: A measure for time-series analysis.
IEEE Signal Processing Letters, 23(5), 610-614.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-ofentropy">
<h3><em>entropy_ofentropy()</em><a class="headerlink" href="#entropy-ofentropy" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_ofentropy">
<span class="sig-name descname"><span class="pre">entropy_ofentropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_ofentropy" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Entropy of entropy (EnofEn)</strong></p>
<p>Entropy of entropy (EnofEn or EoE) combines the features of <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-func docutils literal notranslate"><span class="pre">MSE</span></code></a>
with an alternate measure of information, called <em>superinformation</em>, used in DNA sequencing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – The size of the windows that the signal is divided into. Also referred to as Tau
<span class="math notranslate nohighlight">\(\tau\)</span>, it represents the scale factor and corresponds to
the amount of coarsegraining.</p></li>
<li><p><strong>bins</strong> (<em>int</em>) – The number of equal-size bins to divide the signal’s range in.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments, such as the logarithmic <code class="docutils literal notranslate"><span class="pre">base</span></code> to use for
<a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">entropy_shannon()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>enofen</strong> (<em>float</em>) – The Entropy of entropy of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used, such as the
average entropy <code class="docutils literal notranslate"><span class="pre">AvEn</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># EnofEn</span>
<span class="gp">In [3]: </span><span class="n">enofen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_ofentropy</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">enofen</span>
<span class="gh">Out[4]: </span><span class="go">3.733783409004101</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Hsu, C. F., Wei, S. Y., Huang, H. P., Hsu, L., Chi, S., &amp; Peng, C. K. (2017). Entropy of
entropy: Measurement of dynamical complexity for biological systems. Entropy, 19(10), 550.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-approximate">
<h3><em>entropy_approximate()</em><a class="headerlink" href="#entropy-approximate" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_approximate">
<span class="sig-name descname"><span class="pre">entropy_approximate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corrected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_approximate" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Approximate entropy (ApEn) and its corrected version (cApEn)</strong></p>
<p>Approximate entropy is a technique used to quantify the amount of regularity and the
unpredictability of fluctuations over time-series data. The advantages of ApEn include lower
computational demand (ApEn can be designed to work for small data samples (&lt; 50 data points)
and can be applied in real time) and less sensitive to noise. However, ApEn is heavily
dependent on the record length and lacks relative consistency.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_approximate()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_apen()</span></code>, and
the corrected version via <code class="docutils literal notranslate"><span class="pre">complexity_capen()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>corrected</strong> (<em>bool</em>) – If true, will compute corrected ApEn (cApEn), see Porta (2007).</p></li>
<li><p><strong>**kwargs</strong> – Other arguments.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_sample</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_fuzzy" title="neurokit2.complexity.entropy_fuzzy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_fuzzy</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>apen</strong> (<em>float</em>) – The approximate entropy of the single time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute approximate entropy.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">apen</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_approximate</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">apen</span>
<span class="gh">Out[4]: </span><span class="go">0.08837414074679684</span>

<span class="gp">In [5]: </span><span class="n">capen</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_approximate</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">capen</span>
<span class="gh">Out[6]: </span><span class="go">0.08907775138332998</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Sabeti, M., Katebi, S., &amp; Boostani, R. (2009). Entropy and complexity measures for EEG signal
classification of schizophrenic and control participants. Artificial intelligence in medicine,
47(3), 263-274.</p></li>
<li><p>Shi, B., Zhang, Y., Yuan, C., Wang, S., &amp; Li, P. (2017). Entropy analysis of short-term
heartbeat interval time series during regular walking. Entropy, 19(10), 568.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-sample">
<h3><em>entropy_sample()</em><a class="headerlink" href="#entropy-sample" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_sample">
<span class="sig-name descname"><span class="pre">entropy_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_sample" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Sample Entropy (SampEn)</strong></p>
<p>Compute the sample entropy (SampEn) of a signal. SampEn is a modification
of ApEn used for assessing complexity of physiological time series signals. It corresponds to
the conditional probability that two vectors that are close to each other for <em>m</em> dimensions
will remain close at the next <em>m + 1</em> component.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_sample()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_sampen()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other arguments.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_approximate" title="neurokit2.complexity.entropy_approximate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_approximate</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_fuzzy" title="neurokit2.complexity.entropy_fuzzy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_fuzzy</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>sampen</strong> (<em>float</em>) – The sample entropy of the single time series.
If undefined conditional probabilities are detected (logarithm
of sum of conditional probabilities is <code class="docutils literal notranslate"><span class="pre">ln(0)</span></code>), <code class="docutils literal notranslate"><span class="pre">np.inf</span></code> will
be returned, meaning it fails to retrieve ‘accurate’ regularity information.
This tends to happen for short data segments, increasing tolerance
levels might help avoid this.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute sample entropy.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">sampen</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_sample</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">sampen</span>
<span class="gh">Out[4]: </span><span class="go">0.07380851770121913</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="entropy-permutation">
<h3><em>entropy_permutation()</em><a class="headerlink" href="#entropy-permutation" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_permutation">
<span class="sig-name descname"><span class="pre">entropy_permutation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corrected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_permutation" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Permutation Entropy (PEn), its Weighted (WPEn) and Conditional (CPEn) forms</strong></p>
<p>Permutation Entropy (PEn) is a robust measure of the complexity of a dynamic system by
capturing the order relations between values of a time series and extracting a probability
distribution of the ordinal patterns (see Henry and Judge, 2019). Using ordinal descriptors
increases robustness to large artifacts occurring with low frequencies. PEn is applicable
for regular, chaotic, noisy, or real-world time series and has been employed in the context of
EEG, ECG, and stock market time series.</p>
<p>Mathematically, it corresponds to the <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-func docutils literal notranslate"><span class="pre">Shannon</span> <span class="pre">entropy</span></code></a> after the
signal has been made discrete (symbolic) by analyzing the permutations in the time-embedded
space.</p>
<p>However, the main shortcoming of traditional PEn is that no information besides the order
structure is retained when extracting the ordinal patterns, which leads to several possible
issues (Fadlallah et al., 2013). The <strong>Weighted PEn</strong> was developped to address these
limitations by incorporating significant information (regarding the amplitude) from the
original time series into the ordinal patterns.</p>
<p>The <strong>Conditional Entropy (CPEn)</strong> was originally defined by Bandt &amp; Pompe as <em>Sorting
Entropy</em>, but recently gained in popularity as conditional through the work of Unakafov et al.
(2014). It describes the average diversity of the ordinal patterns succeeding a given ordinal
pattern (dimension+1 vs. dimension).</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_permutation()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_pe()</span></code>.
Moreover, variants can be directly accessed via <code class="docutils literal notranslate"><span class="pre">complexity_wpe()</span></code> and <code class="docutils literal notranslate"><span class="pre">complexity_mspe()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>corrected</strong> (<em>bool</em>) – If True, divide by log2(factorial(m)) to normalize the entropy between 0 and 1. Otherwise,
return the permutation entropy in bit.</p></li>
<li><p><strong>weighted</strong> (<em>bool</em>) – If True, compute the weighted permutation entropy (WPE).</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments, such as a function to compute Entropy (<code class="xref py py-func docutils literal notranslate"><span class="pre">nk.entropy_shannon()</span></code>
(default), <code class="xref py py-func docutils literal notranslate"><span class="pre">nk.entropy_tsallis()</span></code> or <code class="xref py py-func docutils literal notranslate"><span class="pre">nk.entropy_reyni()</span></code>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>PEn</strong> (<em>float</em>) – Permutation Entropy</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_ordinalpatterns" title="neurokit2.complexity.complexity_ordinalpatterns"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_ordinalpatterns</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># Permutation Entropy (uncorrected)</span>
<span class="gp">In [2]: </span><span class="n">pen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_permutation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">pen</span>
<span class="gh">Out[3]: </span><span class="go">2.581868005242452</span>

<span class="go"># Weighted Permutation Entropy (WPEn)</span>
<span class="gp">In [4]: </span><span class="n">wpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_permutation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">wpen</span>
<span class="gh">Out[5]: </span><span class="go">0.9972734114457702</span>

<span class="go"># Conditional Permutation Entropy (CPEn)</span>
<span class="gp">In [6]: </span><span class="n">cpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_permutation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">conditional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">cpen</span>
<span class="gh">Out[7]: </span><span class="go">0.4281923302479203</span>

<span class="go"># Conditional Weighted Permutation Entropy (CWPEn)</span>
<span class="gp">In [8]: </span><span class="n">cwpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_permutation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">conditional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">cwpen</span>
<span class="gh">Out[9]: </span><span class="go">0.40905754810307754</span>

<span class="go"># Conditional Renyi Permutation Entropy (CRPEn)</span>
<span class="gp">In [10]: </span><span class="n">crpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_permutation</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">conditional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">nk</span><span class="o">.</span><span class="n">entropy_renyi</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">crpen</span>
<span class="gh">Out[11]: </span><span class="go">0.29173711228389515</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Fadlallah, B., Chen, B., Keil, A., &amp; Principe, J. (2013). Weighted-permutation entropy: A
complexity measure for time series incorporating amplitude information. Physical Review E, 87
(2), 022911.</p></li>
<li><p>Zanin, M., Zunino, L., Rosso, O. A., &amp; Papo, D. (2012). Permutation entropy and its main
biomedical and econophysics applications: a review. Entropy, 14(8), 1553-1577.</p></li>
<li><p>Bandt, C., &amp; Pompe, B. (2002). Permutation entropy: a natural complexity measure for time
series. Physical review letters, 88(17), 174102.</p></li>
<li><p>Unakafov, A. M., &amp; Keller, K. (2014). Conditional entropy of ordinal patterns. Physica D:
Nonlinear Phenomena, 269, 94-102.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-bubble">
<h3><em>entropy_bubble()</em><a class="headerlink" href="#entropy-bubble" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_bubble">
<span class="sig-name descname"><span class="pre">entropy_bubble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_bubble" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Bubble Entropy (BubblEn)</strong></p>
<p>Introduced by Manis et al. (2017) with the goal of being independent of parameters such as
<em>Tolerance</em> and <em>Dimension</em>. Bubble Entropy is based on <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation</span> <span class="pre">entropy</span></code></a>,
but uses the bubble sort algorithm for the ordering procedure instead of the number of swaps
performed for each vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The <em>alpha</em> <span class="math notranslate nohighlight">\(\alpha\)</span> parameter (default to 1) for <a class="reference internal" href="#neurokit2.complexity.entropy_renyi" title="neurokit2.complexity.entropy_renyi"><code class="xref py py-func docutils literal notranslate"><span class="pre">Rényi</span> <span class="pre">entropy</span></code></a>).</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other arguments.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_ordinalpatterns" title="neurokit2.complexity.complexity_ordinalpatterns"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_ordinalpatterns</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_permutation</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_renyi" title="neurokit2.complexity.entropy_renyi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_renyi</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>BubbEn</strong> (<em>float</em>) – The Bubble Entropy.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute sample entropy.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">BubbEn</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_bubble</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">BubbEn</span>
<span class="gh">Out[4]: </span><span class="go">0.07799253889312076</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Manis, G., Aktaruzzaman, M. D., &amp; Sassi, R. (2017). Bubble entropy: An entropy almost free of
parameters. IEEE Transactions on Biomedical Engineering, 64(11), 2711-2718.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-range">
<h3><em>entropy_range()</em><a class="headerlink" href="#entropy-range" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_range">
<span class="sig-name descname"><span class="pre">entropy_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_range" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Range Entropy (RangeEn)</strong></p>
<p>Introduced by <a class="reference external" href="https://www.mdpi.com/1099-4300/20/12/962/htm">Omidvarnia et al. (2018)</a>,
RangeEn refers to a modified form of SampEn (or ApEn).</p>
<p>Both ApEn and SampEn compute the logarithmic likelihood that runs of patterns that are close
remain close on the next incremental comparisons, of which this closeness is estimated by the
Chebyshev distance. Range Entropy uses instead a normalized “range distance”, resulting in
modified forms of ApEn and SampEn, <strong>RangeEn (A)</strong> (<em>mApEn</em>) and <strong>RangeEn (B)</strong> (<em>mSampEn</em>).</p>
<p>However, the RangeEn (A), based on ApEn, often yields undefined entropies (i.e., <em>NaN</em> or
<em>Inf</em>). As such, using RangeEn (B) is recommended instead.</p>
<p>RangeEn is described as more robust to nonstationary signal changes, and has a more linear
relationship with the Hurst exponent (compared to ApEn and SampEn), and has no need for signal
amplitude correction.</p>
<p>Note that the <a class="reference internal" href="#neurokit2.complexity.entropy_approximate" title="neurokit2.complexity.entropy_approximate"><code class="xref py py-func docutils literal notranslate"><span class="pre">corrected</span></code></a> version of ApEn (cApEn) can be computed
by setting <code class="docutils literal notranslate"><span class="pre">corrected=True</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>approximate</strong> (<em>bool</em>) – The entropy algorithm to use. If <code class="docutils literal notranslate"><span class="pre">False</span></code> (default), will use sample entropy and return
<em>mSampEn</em> (<strong>RangeEn B</strong>). If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will use approximate entropy and return <em>mApEn</em>
(<strong>RangeEn A</strong>).</p></li>
<li><p><strong>**kwargs</strong> – Other arguments.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_approximate" title="neurokit2.complexity.entropy_approximate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_approximate</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_sample</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>RangeEn</strong> (<em>float</em>) – Range Entropy. If undefined conditional probabilities are detected (logarithm
of sum of conditional probabilities is <code class="docutils literal notranslate"><span class="pre">ln(0)</span></code>), <code class="docutils literal notranslate"><span class="pre">np.inf</span></code> will
be returned, meaning it fails to retrieve ‘accurate’ regularity information.
This tends to happen for short data segments, increasing tolerance
levels might help avoid this.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="go"># Range Entropy B (mSampEn)</span>
<span class="gp">In [3]: </span><span class="n">RangeEnB</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_range</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">RangeEnB</span>
<span class="gh">Out[4]: </span><span class="go">1.0882982278736182</span>

<span class="go"># Range Entropy A (mApEn)</span>
<span class="gp">In [5]: </span><span class="n">RangeEnA</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_range</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">RangeEnA</span>
<span class="gh">Out[6]: </span><span class="go">1.0749312293123292</span>

<span class="go"># Range Entropy A (corrected)</span>
<span class="gp">In [7]: </span><span class="n">RangeEnAc</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_range</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">RangeEnAc</span>
<span class="gh">Out[8]: </span><span class="go">1.1153142451616476</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Omidvarnia, A., Mesbah, M., Pedersen, M., &amp; Jackson, G. (2018). Range entropy: A bridge
between signal complexity and self-similarity. Entropy, 20(12), 962.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-fuzzy">
<h3><em>entropy_fuzzy()</em><a class="headerlink" href="#entropy-fuzzy" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_fuzzy">
<span class="sig-name descname"><span class="pre">entropy_fuzzy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_fuzzy" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Fuzzy Entropy (FuzzyEn)</strong></p>
<p>Fuzzy entropy (FuzzyEn) of a signal stems from the combination between information theory and
fuzzy set theory (Zadeh, 1965). A fuzzy set is a set containing elements with varying degrees of
membership.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_fuzzy()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_fuzzyen()</span></code>, or
<code class="docutils literal notranslate"><span class="pre">complexity_fuzzyapen()</span></code> for its approximate version. Note that the fuzzy corrected
approximate entropy (cApEn) can also be computed via setting <code class="docutils literal notranslate"><span class="pre">corrected=True</span></code> (see examples).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fuzzyen</strong> (<em>float</em>) – The fuzzy entropy of the single time series.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute fuzzy entropy.</p></li>
<li><p><strong>approximate</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will compute the fuzzy approximate entropy (FuzzyApEn).</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_sample</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<p>..ipython:: python</p>
<blockquote>
<div><p>import neurokit2 as nk</p>
<p>signal = nk.signal_simulate(duration=2, frequency=5)</p>
<p>fuzzyen, parameters = nk.entropy_fuzzy(signal)
fuzzyen</p>
<p>fuzzyapen, parameters = nk.entropy_fuzzy(signal, approximate=True)
fuzzyapen</p>
<p>fuzzycapen, parameters = nk.entropy_fuzzy(signal, approximate=True, corrected=True)
fuzzycapen</p>
</div></blockquote>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Ishikawa, A., &amp; Mieno, H. (1979). The fuzzy entropy concept and its application. Fuzzy Sets
and systems, 2(2), 113-123.</p></li>
<li><p>Zadeh, L. A. (1996). Fuzzy sets. In Fuzzy sets, fuzzy logic, and fuzzy systems: selected
papers by Lotfi A Zadeh (pp. 394-432).</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-multiscale">
<h3><em>entropy_multiscale()</em><a class="headerlink" href="#entropy-multiscale" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_multiscale">
<span class="sig-name descname"><span class="pre">entropy_multiscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MSEn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_multiscale" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Multiscale entropy (MSEn) and its Composite (CMSEn), Refined (RCMSEn) or fuzzy versions</strong></p>
<p>One of the limitation of <a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">SampEn</span></code></a> is that it characterizes
complexity strictly on the time scale defined by the sampling procedure (via the <code class="docutils literal notranslate"><span class="pre">delay</span></code>
argument). To address this, Costa et al. (2002) proposed the multiscale entropy (MSEn),
which compute sample entropies at multiple scales.</p>
<p>The conventional MSEn algorithm consists of two steps:</p>
<ol class="arabic simple">
<li><p>A <a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-func docutils literal notranslate"><span class="pre">coarse-graining</span></code></a> procedure is used to represent the
signal at different time scales.</p></li>
<li><p><a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">Sample</span> <span class="pre">entropy</span></code></a> (or other function) is used to quantify the
regularity of a coarse-grained time series at each time scale factor.</p></li>
</ol>
<p>However, in the traditional coarse-graining procedure, the larger the scale factor is, the
shorter the coarse-grained time series is. As such, the variance of the entropy of the
coarse-grained series estimated by SampEn increases as the time scale factor increases, making
it problematic for shorter signals.</p>
<ul class="simple">
<li><p><strong>CMSEn</strong>: In order to reduce the variance of estimated entropy values at large scales, Wu et
al. (2013) introduced the <strong>Composite Multiscale Entropy</strong> algorithm, which computes
multiple coarse-grained series for each scale factor (via the <strong>time-shift</strong> method for
<a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-func docutils literal notranslate"><span class="pre">coarse-graining</span></code></a>).</p></li>
<li><p><strong>RCMSEn</strong>: Wu et al. (2014) further <strong>Refined</strong> their CMSEn by averaging not the entropy
values of each subcoarsed vector, but its components at a lower level.</p></li>
<li><p><strong>MMSEn</strong>: Wu et al. (2013) also introduced the <strong>Modified Multiscale Entropy</strong>
algorithm, which is based on rolling-average <a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-func docutils literal notranslate"><span class="pre">coarse-graining</span></code></a>.</p></li>
<li><p><strong>IMSEn</strong>: Liu et al. (2012) introduced an adaptive-resampling procedure to resample the
coarse-grained series. We implement a generalization of this via interpolation that can be
referred to as <strong>Interpolated Multiscale Entropy</strong>.</p></li>
</ul>
<p>Their <a class="reference internal" href="#neurokit2.complexity.entropy_fuzzy" title="neurokit2.complexity.entropy_fuzzy"><code class="xref py py-func docutils literal notranslate"><span class="pre">Fuzzy</span></code></a> version can be obtained by setting <code class="docutils literal notranslate"><span class="pre">fuzzy=True</span></code>.</p>
<p>This function can be called either via <code class="docutils literal notranslate"><span class="pre">entropy_multiscale()</span></code> or <code class="docutils literal notranslate"><span class="pre">complexity_mse()</span></code>.
Moreover, variants can be directly accessed via <code class="docutils literal notranslate"><span class="pre">complexity_cmse()</span></code>, <cite>complexity_rcmse()`</cite>,
<code class="docutils literal notranslate"><span class="pre">complexity_fuzzymse()</span></code>, <code class="docutils literal notranslate"><span class="pre">complexity_fuzzycmse()</span></code> and <code class="docutils literal notranslate"><span class="pre">complexity_fuzzyrcmse()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.
or dataframe.</p></li>
<li><p><strong>scale</strong> (<em>str or int or list</em>) – A list of scale factors used for coarse graining the time series. If ‘default’, will use
<code class="docutils literal notranslate"><span class="pre">range(len(signal)</span> <span class="pre">/</span> <span class="pre">(dimension</span> <span class="pre">+</span> <span class="pre">10))</span></code> (see discussion
<a class="reference external" href="https://github.com/neuropsychology/NeuroKit/issues/75#issuecomment-583884426">here</a>).
If ‘max’, will use all scales until half the length of the signal. If an integer, will
create a range until the specified int. See <a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_coarsegraining()</span></code></a> for details.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – What version of multiscale entropy to compute. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;MSEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;CMSEn&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;RCMSEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MMSEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;IMSEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MSApEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MSPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;CMSPEn&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;MMSPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;IMSPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MSWPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;CMSWPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MMSWPEn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;IMSWPEn&quot;</span></code>
(case sensitive).</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Show the entropy values for each scale factor.</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>float</em> – The point-estimate of multiscale entropy (MSEn) of the single time series corresponding to
the area under the MSEn values curve, which is essentially the sum of sample entropy values
over the range of scale factors.</p></li>
<li><p><em>dict</em> – A dictionary containing additional information regarding the parameters used
to compute multiscale entropy. The entropy values corresponding to each <code class="docutils literal notranslate"><span class="pre">&quot;Scale&quot;</span></code>
factor are stored under the <code class="docutils literal notranslate"><span class="pre">&quot;Value&quot;</span></code> key.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_coarsegraining</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_sample" title="neurokit2.complexity.entropy_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_sample</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_fuzzy" title="neurokit2.complexity.entropy_fuzzy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_fuzzy</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_permutation</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<p><strong>MSEn</strong> (basic coarse-graining)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">40</span><span class="p">])</span>

<span class="gp">In [3]: </span><span class="n">msen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale1.png"><img alt="savefig/p_entropy_multiscale1.png" src="savefig/p_entropy_multiscale1.png" /></a>
<p><strong>CMSEn</strong> (time-shifted coarse-graining)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">cmsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;CMSEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale2.png"><img alt="savefig/p_entropy_multiscale2.png" src="savefig/p_entropy_multiscale2.png" /></a>
<p><strong>RCMSEn</strong> (refined composite MSEn)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">rcmsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;RCMSEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale3.png"><img alt="savefig/p_entropy_multiscale3.png" src="savefig/p_entropy_multiscale3.png" /></a>
<p><strong>MMSEn</strong> (rolling-window coarse-graining)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">mmsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MMSEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale4.png"><img alt="savefig/p_entropy_multiscale4.png" src="savefig/p_entropy_multiscale4.png" /></a>
<p><strong>IMSEn</strong> (interpolated coarse-graining)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="n">imsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;IMSEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale5.png"><img alt="savefig/p_entropy_multiscale5.png" src="savefig/p_entropy_multiscale5.png" /></a>
<p><strong>MSApEn</strong> (based on ApEn instead of SampEn)</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [8]: </span><span class="n">msapen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSApEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale6.png"><img alt="savefig/p_entropy_multiscale6.png" src="savefig/p_entropy_multiscale6.png" /></a>
<p><strong>MSPEn</strong> (based on PEn), <strong>CMSPEn</strong>, <strong>MMSPEn</strong> and <strong>IMSPEn</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">mspen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSPEn&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale7.png"><img alt="savefig/p_entropy_multiscale7.png" src="savefig/p_entropy_multiscale7.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [10]: </span><span class="n">cmspen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;CMSPEn&quot;</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">cmspen</span>
<span class="gh">Out[11]: </span><span class="go">0.9831935684217636</span>

<span class="gp">In [12]: </span><span class="n">mmspen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MMSPEn&quot;</span><span class="p">)</span>

<span class="gp">In [13]: </span><span class="n">mmspen</span>
<span class="gh">Out[13]: </span><span class="go">0.993541957922471</span>

<span class="gp">In [14]: </span><span class="n">imspen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;IMSPEn&quot;</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">imspen</span>
<span class="gh">Out[15]: </span><span class="go">0.9846132146225728</span>
</pre></div>
</div>
<p><strong>MSWPEn</strong> (based on WPEn), <strong>CMSWPEn</strong>, <strong>MMSWPEn</strong> and <strong>IMSWPEn</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [16]: </span><span class="n">mswpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSWPEn&quot;</span><span class="p">)</span>

<span class="gp">In [17]: </span><span class="n">cmswpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;CMSWPEn&quot;</span><span class="p">)</span>

<span class="gp">In [18]: </span><span class="n">mmswpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MMSWPEn&quot;</span><span class="p">)</span>

<span class="gp">In [19]: </span><span class="n">imswpen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;IMSWPEn&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>FuzzyMSEn</strong>, <strong>FuzzyCMSEn</strong> and <strong>FuzzyRCMSEn</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [20]: </span><span class="n">fuzzymsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MSEn&quot;</span><span class="p">,</span> <span class="n">fuzzy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_multiscale8.png"><img alt="savefig/p_entropy_multiscale8.png" src="savefig/p_entropy_multiscale8.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [21]: </span><span class="n">fuzzycmsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;CMSEn&quot;</span><span class="p">,</span> <span class="n">fuzzy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [22]: </span><span class="n">fuzzycmsen</span>
<span class="gh">Out[22]: </span><span class="go">1.6913277708234369</span>

<span class="gp">In [23]: </span><span class="n">fuzzyrcmsen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;RCMSEn&quot;</span><span class="p">,</span> <span class="n">fuzzy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [24]: </span><span class="n">fuzzycmsen</span>
<span class="gh">Out[24]: </span><span class="go">1.6913277708234369</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Costa, M., Goldberger, A. L., &amp; Peng, C. K. (2002). Multiscale entropy analysis of complex
physiologic time series. Physical review letters, 89(6), 068102.</p></li>
<li><p>Costa, M., Goldberger, A. L., &amp; Peng, C. K. (2005). Multiscale entropy analysis of biological
signals. Physical review E, 71(2), 021906.</p></li>
<li><p>Wu, S. D., Wu, C. W., Lee, K. Y., &amp; Lin, S. G. (2013). Modified multiscale entropy for
short-term time series analysis. Physica A: Statistical Mechanics and its Applications, 392
(23), 5865-5873.</p></li>
<li><p>Wu, S. D., Wu, C. W., Lin, S. G., Wang, C. C., &amp; Lee, K. Y. (2013). Time series analysis
using composite multiscale entropy. Entropy, 15(3), 1069-1084.</p></li>
<li><p>Wu, S. D., Wu, C. W., Lin, S. G., Lee, K. Y., &amp; Peng, C. K. (2014). Analysis of complex time
series using refined composite multiscale entropy. Physics Letters A, 378(20), 1369-1374.</p></li>
<li><p>Gow, B. J., Peng, C. K., Wayne, P. M., &amp; Ahn, A. C. (2015). Multiscale entropy analysis of
center-of-pressure dynamics in human postural control: methodological considerations. Entropy,
17(12), 7926-7947.</p></li>
<li><p>Norris, P. R., Anderson, S. M., Jenkins, J. M., Williams, A. E., &amp; Morris Jr, J. A. (2008).
Heart rate multiscale entropy at three hours predicts hospital mortality in 3,154 trauma
patients. Shock, 30(1), 17-22.</p></li>
<li><p>Liu, Q., Wei, Q., Fan, S. Z., Lu, C. W., Lin, T. Y., Abbod, M. F., &amp; Shieh, J. S. (2012).
Adaptive computation of multiscale entropy and its application in EEG signals for monitoring
depth of anesthesia during surgery. Entropy, 14(6), 978-992.</p></li>
</ul>
</dd></dl>

</section>
<section id="entropy-hierarchical">
<h3><em>entropy_hierarchical()</em><a class="headerlink" href="#entropy-hierarchical" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.entropy_hierarchical">
<span class="sig-name descname"><span class="pre">entropy_hierarchical</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.entropy_hierarchical" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Hierarchical Entropy (HEn)</strong></p>
<p>Hierarchical Entropy (HEn) can be viewed as a generalization of the multiscale
decomposition used in <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-func docutils literal notranslate"><span class="pre">multiscale</span> <span class="pre">entropy</span></code></a>, and the Haar wavelet
decomposition since it generate subtrees of the hierarchical tree. It preserves the strength of
the multiscale decomposition with additional components of higher frequency in different
scales. The hierarchical decomposition, unlike the wavelet decomposition, contains redundant
components, which makes it sensitive to the dynamical richness of the time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – The maximum scale factor. Can only be a number of “default”. Though it behaves a bit
differently here, see <code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_multiscale()</span></code> for details.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Method for symbolic sequence partitioning. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;MEP&quot;</span></code> (default),
<code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;uniform&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;kmeans&quot;</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other keyword arguments (currently not used).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>SyDyEn</strong> (<em>float</em>) – Symbolic Dynamic Entropy (SyDyEn) of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_multiscale</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a Signal</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">97</span><span class="p">,</span> <span class="mi">98</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="go"># Compute Hierarchical Entropy (HEn)</span>
<span class="gp">In [3]: </span><span class="n">hen</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_hierarchical</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_entropy_hierarchical1.png"><img alt="savefig/p_entropy_hierarchical1.png" src="savefig/p_entropy_hierarchical1.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Jiang, Y., Peng, C. K., &amp; Xu, Y. (2011). Hierarchical entropy analysis for biological
signals. Journal of Computational and Applied Mathematics, 236(5), 728-742.</p></li>
<li><p>Li, W., Shen, X., &amp; Li, Y. (2019). A comparative study of multiscale sample entropy and
hierarchical entropy and its application in feature extraction for ship-radiated noise.
Entropy, 21(8), 793.</p></li>
</ul>
</dd></dl>

</section>
</section>
<section id="other">
<h2>Other<a class="headerlink" href="#other" title="Permalink to this headline">#</a></h2>
<section id="fisher-information">
<h3><em>fisher_information()</em><a class="headerlink" href="#fisher-information" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fisher_information">
<span class="sig-name descname"><span class="pre">fisher_information</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fisher_information" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Fisher Information (FI)</strong></p>
<p>The Fisher information was introduced by R. A. Fisher in 1925, as a measure of “intrinsic
accuracy” in statistical estimation theory. It is central to many statistical fields far beyond
that of complexity theory. It measures the amount of information that an observable random
variable carries about an unknown parameter. In complexity analysis, the amount of information
that a system carries “about itself” is measured. Similarly to <a class="reference internal" href="#neurokit2.complexity.entropy_svd" title="neurokit2.complexity.entropy_svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">SVDEn</span></code></a>, it
is based on the Singular Value Decomposition (SVD) of the <code class="xref py py-func docutils literal notranslate"><span class="pre">time-delay</span> <span class="pre">embedded</span></code>
signal. The value of FI is usually anti-correlated with other measures of complexity (the more
information a system withholds about itself, and the more predictable and thus, less complex it
is).</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_svd" title="neurokit2.complexity.entropy_svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_svd</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">mutual_information</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embedding</span></code>, <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fi</strong> (<em>float</em>) – The computed fisher information measure.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute fisher information.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">fi</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fisher_information</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">fi</span>
<span class="gh">Out[4]: </span><span class="go">0.6424727558784687</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="complexity-hjorth">
<h3><em>complexity_hjorth()</em><a class="headerlink" href="#complexity-hjorth" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_hjorth">
<span class="sig-name descname"><span class="pre">complexity_hjorth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_hjorth" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Hjorth’s Complexity and Parameters</strong></p>
<p>Hjorth Parameters are indicators of statistical properties initially introduced by Hjorth
(1970) to describe the general characteristics of an EEG trace in a few quantitative terms, but
which can applied to any time series. The parameters are activity, mobility, and complexity.
NeuroKit returns complexity directly in the output tuple, but the other parameters can be found
in the dictionary.</p>
<ul>
<li><p>The <strong>activity</strong> parameter is simply the variance of the signal, which corresponds to the
mean power of a signal (if its mean is 0).</p>
<div class="math notranslate nohighlight">
\[Activity = \sigma_{signal}^2\]</div>
</li>
<li><p>The <strong>complexity</strong> parameter gives an estimate of the bandwidth of the signal, which
indicates the similarity of the shape of the signal to a pure sine wave (for which the
value converges to 1). In other words, it is a measure of the “excessive details” with
reference to the “softest” possible curve shape. The Complexity parameter is defined as the
ratio of the mobility of the first derivative of the signal to the mobility of the signal.</p>
<div class="math notranslate nohighlight">
\[Complexity = \sigma_{d}/ \sigma_{signal}\]</div>
</li>
<li><p>The <strong>mobility</strong> parameter represents the mean frequency or the proportion of standard
deviation of the power spectrum. This is defined as the square root of variance of the
first derivative of the signal divided by the variance of the signal.</p>
<div class="math notranslate nohighlight">
\[Mobility = \frac{\sigma_{dd}/ \sigma_{d}}{Complexity}\]</div>
</li>
</ul>
<p><span class="math notranslate nohighlight">\(d\)</span> and <span class="math notranslate nohighlight">\(dd\)</span> represent the first and second derivatives of the signal, respectively.</p>
<p>Hjorth (1970) illustrated the parameters as follows:</p>
<figure class="align-default">
<a class="reference external image-reference" href="http://dx.doi.org/10.1016/0013-4694(70)90143-4"><img alt="Figure from Hjorth (1970)." src="../_images/hjorth1970.png" /></a>
</figure>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>hjorth</strong> (<em>float</em>) – Hjorth’s Complexity.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing the additional Hjorth parameters, such as <code class="docutils literal notranslate"><span class="pre">'Mobility'</span></code> and
<code class="docutils literal notranslate"><span class="pre">'Activity'</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate a signal with duration os 2s</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go"># Compute Hjorth&#39;s Complexity</span>
<span class="gp">In [3]: </span><span class="n">complexity</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_hjorth</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">complexity</span>
<span class="gh">Out[4]: </span><span class="go">1.0010008861067599</span>

<span class="gp">In [5]: </span><span class="n">info</span>
<span class="gh">Out[5]: </span><span class="go">{&#39;Mobility&#39;: 0.03140677206992582, &#39;Activity&#39;: 0.125}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Hjorth, B (1970) EEG Analysis Based on Time Domain Properties. Electroencephalography and
Clinical Neurophysiology, 29, 306-310. <a class="reference external" href="http://dx.doi.org/10.1016/0013-4694(70)90143-4">http://dx.doi.org/10.1016/0013-4694(70)90143-4</a></p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-lempelziv">
<h3><em>complexity_lempelziv()</em><a class="headerlink" href="#complexity-lempelziv" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_lempelziv">
<span class="sig-name descname"><span class="pre">complexity_lempelziv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">permutation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_lempelziv" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Lempel-Ziv Complexity (LZC, PLZC and MSLZC)</strong></p>
<p>Computes Lempel-Ziv Complexity (LZC) to quantify the regularity of the signal, by scanning
symbolic sequences for new patterns, increasing the complexity count every time a new sequence
is detected. Regular signals have a lower number of distinct patterns and thus have low LZC
whereas irregular signals are characterized by a high LZC. While often being interpreted as a
complexity measure, LZC was originally proposed to reflect randomness (Lempel and Ziv, 1976).</p>
<p>Permutation Lempel-Ziv Complexity (<strong>PLZC</strong>) combines LZC with <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation</span></code></a>.
A sequence of symbols is generated from the permutations observed in the <code class="xref py py-func docutils literal notranslate"><span class="pre">tine-delay</span>
<span class="pre">embedding</span></code>, and LZC is computed over it.</p>
<p>Multiscale (Permutation) Lempel-Ziv Complexity (<strong>MSLZC</strong> or <strong>MSPLZC</strong>) combines permutation
LZC with the <a class="reference internal" href="#neurokit2.complexity.entropy_multiscale" title="neurokit2.complexity.entropy_multiscale"><code class="xref py py-func docutils literal notranslate"><span class="pre">multiscale</span> <span class="pre">approach</span></code></a>. It first performs a
<a class="reference internal" href="#neurokit2.complexity.complexity_coarsegraining" title="neurokit2.complexity.complexity_coarsegraining"><code class="xref py py-func docutils literal notranslate"><span class="pre">coarse-graining</span></code></a> procedure to the original time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter. Only used
when <code class="docutils literal notranslate"><span class="pre">permutation=True</span></code>.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter. Only used
when <code class="docutils literal notranslate"><span class="pre">permutation=True</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments to be passed to <a class="reference internal" href="#neurokit2.complexity.complexity_ordinalpatterns" title="neurokit2.complexity.complexity_ordinalpatterns"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_ordinalpatterns()</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">permutation=True</span></code>) or <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>lzc</strong> (<em>float</em>) – Lempel Ziv Complexity (LZC) of the signal.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute LZC.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_symbolize</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_ordinalpatterns" title="neurokit2.complexity.complexity_ordinalpatterns"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_ordinalpatterns</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_permutation</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># LZC</span>
<span class="gp">In [3]: </span><span class="n">lzc</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_lempelziv</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">lzc</span>
<span class="gh">Out[4]: </span><span class="go">1.0804820237218407</span>

<span class="go"># PLZC</span>
<span class="gp">In [5]: </span><span class="n">plzc</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_lempelziv</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">permutation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">plzc</span>
<span class="gh">Out[6]: </span><span class="go">0.6883678475327589</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># MSLZC</span>
<span class="gp">In [7]: </span><span class="n">mslzc</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;LZC&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_lempelziv1.png"><img alt="savefig/p_complexity_lempelziv1.png" src="savefig/p_complexity_lempelziv1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># MSPLZC</span>
<span class="gp">In [8]: </span><span class="n">msplzc</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">entropy_multiscale</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;LZC&quot;</span><span class="p">,</span> <span class="n">permutation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_lempelziv2.png"><img alt="savefig/p_complexity_lempelziv2.png" src="savefig/p_complexity_lempelziv2.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Lempel, A., &amp; Ziv, J. (1976). On the complexity of finite sequences. IEEE Transactions on
information theory, 22(1), 75-81.</p></li>
<li><p>Nagarajan, R. (2002). Quantifying physiological data with Lempel-Ziv complexity-certain
issues. IEEE Transactions on Biomedical Engineering, 49(11), 1371-1373.</p></li>
<li><p>Kaspar, F., &amp; Schuster, H. G. (1987). Easily calculable measure for the complexity of
spatiotemporal patterns. Physical Review A, 36(2), 842.</p></li>
<li><p>Zhang, Y., Hao, J., Zhou, C., &amp; Chang, K. (2009). Normalized Lempel-Ziv complexity and
its application in bio-sequence analysis. Journal of mathematical chemistry, 46(4), 1203-1212.</p></li>
<li><p>Bai, Y., Liang, Z., &amp; Li, X. (2015). A permutation Lempel-Ziv complexity measure for EEG
analysis. Biomedical Signal Processing and Control, 19, 102-114.</p></li>
<li><p>Borowska, M. (2021). Multiscale Permutation Lempel-Ziv Complexity Measure for Biomedical
Signal Analysis: Interpretation and Application to Focal EEG Signals. Entropy, 23(7), 832.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-relativeroughness">
<h3><em>complexity_relativeroughness()</em><a class="headerlink" href="#complexity-relativeroughness" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_relativeroughness">
<span class="sig-name descname"><span class="pre">complexity_relativeroughness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_relativeroughness" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Relative Roughness (RR)</strong></p>
<p>Relative Roughness is a ratio of local variance (autocovariance at lag-1) to global variance
(autocovariance at lag-0) that can be used to classify different ‘noises’
(see <a class="reference external" href="https://complexity-methods.github.io/book/relative-roughness.html">Hasselman, 2019</a>).
It can also be used as an index to test for the applicability of fractal analysis (see
<a class="reference external" href="https://doi.org/10.3389/fphys.2012.00208">Marmelat et al., 2012</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other arguments to be passed to <code class="docutils literal notranslate"><span class="pre">nk.signal_autocor()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>rr</strong> (<em>float</em>) – The RR value.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute RR.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">rr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_relativeroughness</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">rr</span>
<span class="gh">Out[4]: </span><span class="go">1.2</span>

<span class="go"># Change autocorrelation method</span>
<span class="gp">In [5]: </span><span class="n">rr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_relativeroughness</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;cor&quot;</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">rr</span>
<span class="gh">Out[6]: </span><span class="go">1.2</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Marmelat, V., Torre, K., &amp; Delignieres, D. (2012). Relative roughness:
an index for testing the suitability of the monofractal model.
Frontiers in Physiology, 3, 208.</p></li>
</ul>
</dd></dl>

</section>
<section id="fractal-hurst">
<h3><em>fractal_hurst()</em><a class="headerlink" href="#fractal-hurst" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_hurst">
<span class="sig-name descname"><span class="pre">fractal_hurst</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corrected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_hurst" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Hurst Exponent (H)</strong></p>
<p>This function estimates the Hurst exponent via the standard rescaled range (R/S) approach, but
other methods exist, such as Detrended Fluctuation Analysis (DFA, see <code class="docutils literal notranslate"><span class="pre">fractal_dfa()</span></code>).</p>
<p>The Hurst exponent is a measure for the “long-term memory” of a signal. It can be used to
determine whether the time series is more, less, or equally likely to increase if it has
increased in previous steps. This property makes the Hurst exponent especially interesting for
the analysis of stock data. It typically ranges from 0 to 1, with 0.5 corresponding to a
Brownian motion. If H &lt; 0.5, the time-series covers less “distance” than a random walk (the
memory of the signal decays faster than at random), and vice versa.</p>
<p>The R/S approach first splits the time series into non-overlapping subseries of length n. R and
S (sigma) are then calculated for each subseries and the mean is taken over all subseries
yielding (R/S)_n. This process is repeated for several lengths <em>n</em>. The final exponent is then
derived from fitting a straight line to the plot of <span class="math notranslate nohighlight">\(log((R/S)_n)\)</span> vs <span class="math notranslate nohighlight">\(log(n)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.
or dataframe.</p></li>
<li><p><strong>scale</strong> (<em>list</em>) – A list containing the lengths of the windows (number of data points in each subseries) that
the signal is divided into. See <code class="xref py py-func docutils literal notranslate"><span class="pre">fractal_dfa()</span></code> for more information.</p></li>
<li><p><strong>corrected</strong> (<em>boolean</em>) – if True, the Anis-Lloyd-Peters correction factor will be applied to the
output according to the expected value for the individual (R/S) values.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If True, returns a plot.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_dfa</span></code></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="go"># Simulate Signal with duration of 2s</span>
<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go"># Compute Hurst Exponent</span>
<span class="gp">In [3]: </span><span class="n">h</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_hurst</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">corrected</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">h</span>
<span class="gh">Out[4]: </span><span class="go">0.9653747932291417</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Brandi, G., &amp; Di Matteo, T. (2021). On the statistics of scaling exponents and the
Multiscaling Value at Risk. The European Journal of Finance, 1-22.</p></li>
<li><p>Annis, A. A., &amp; Lloyd, E. H. (1976). The expected value of the adjusted rescaled Hurst range
of independent normal summands. Biometrika, 63(1), 111-116.</p></li>
<li><p><a class="reference external" href="https://github.com/CSchoel/nolds">https://github.com/CSchoel/nolds</a></p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-lyapunov">
<h3><em>complexity_lyapunov()</em><a class="headerlink" href="#complexity-lyapunov" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_lyapunov">
<span class="sig-name descname"><span class="pre">complexity_lyapunov</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rosenstein1993'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">len_trajectory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">matrix_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_lyapunov" title="Permalink to this definition">#</a></dt>
<dd><p><strong>(Largest) Lyapunov Exponent (LLE)</strong></p>
<p>Lyapunov exponents (LE) describe the rate of exponential separation (convergence or divergence)
of nearby trajectories of a dynamical system. It is a measure of sensitive dependence on
initial conditions, i.e. how quickly two nearby states diverge. A system can have multiple LEs,
equal to thenumber of the dimensionality of the phase space, and the largest LE value, “LLE” is
often used to determine the overall predictability of the dynamical system.</p>
<p>Different algorithms exist to estimate these indices:</p>
<ul class="simple">
<li><p><strong>Rosenstein et al.’s (1993)</strong> algorithm was designed for calculating LLEs from small datasets.
The time series is first reconstructed using a delay-embedding method, and the closest
neighbour of each vector is computed using the euclidean distance. These two neighbouring
points are then tracked along their distance trajectories for a number of data points. The
slope of the line using a least-squares fit of the mean log trajectory of the distances gives
the final LLE.</p></li>
<li><p><strong>Eckmann et al. (1996)</strong> computes LEs by first reconstructing the time series using a
delay-embedding method, and obtains the tangent that maps to the reconstructed dynamics using
a least-squares fit, where the LEs are deduced from the tangent maps.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The <strong>Eckman (1996)</strong> method currently does not work. Please help us fixing it by double
checking the code, the paper and helping us figuring out what’s wrong. Overall, we would like
to improve this function to return for instance all the exponents (Lyapunov spectrum),
implement newer and faster methods (e.g., Balcerzak, 2018, 2020), etc. If you’re interested
in helping out with this, please get in touch!</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter. If method
is <code class="docutils literal notranslate"><span class="pre">&quot;eckmann1996&quot;</span></code>, larger values for dimension are recommended.</p></li>
<li><p><strong>tolerance</strong> (<em>int</em>) – Minimum temporal separation (tolerance) between two neighbors. If ‘default’, finds a
suitable value by calculating the mean period of the data, obtained by the reciprocal of
the mean frequency of the power spectrum.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – The method that defines the algorithm for computing LE. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;rosenstein1993&quot;</span></code>
or <code class="docutils literal notranslate"><span class="pre">&quot;eckmann1996&quot;</span></code>.</p></li>
<li><p><strong>len_trajectory</strong> (<em>int</em>) – Applies when method is <code class="docutils literal notranslate"><span class="pre">&quot;rosenstein1993&quot;</span></code>. The number of data points in which
neighboring trajectories are followed.</p></li>
<li><p><strong>matrix_dim</strong> (<em>int</em>) – Applies when method is <code class="docutils literal notranslate"><span class="pre">&quot;eckmann1996&quot;</span></code>. Corresponds to the number of LEs to return.</p></li>
<li><p><strong>min_neighbors</strong> (<em>int, str</em>) – Applies when method is <code class="docutils literal notranslate"><span class="pre">&quot;eckmann1996&quot;</span></code>. Minimum number of neighbors. If <code class="docutils literal notranslate"><span class="pre">&quot;default&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">min(2</span> <span class="pre">*</span> <span class="pre">matrix_dim,</span> <span class="pre">matrix_dim</span> <span class="pre">+</span> <span class="pre">4)</span></code> is used.</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Other arguments to be passed to <code class="docutils literal notranslate"><span class="pre">signal_psd()</span></code> for calculating the minimum temporal
separation of two neighbors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>lle</strong> (<em>float</em>) – An estimate of the largest Lyapunov exponent (LLE) if method is ‘rosenstein1993’, and
an array of LEs if ‘eckmann1996’.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used
to compute LLE.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">lle</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_lyapunov</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;rosenstein1993&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">lle</span>
<span class="gh">Out[4]: </span><span class="go">0.042374956576384785</span>

<span class="go"># Eckman&#39;s method is broken. Please help us fix-it!</span>
<span class="go"># lle, info = nk.complexity_lyapunov(signal, dimension=2, method=&quot;eckmann1996&quot;)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rosenstein, M. T., Collins, J. J., &amp; De Luca, C. J. (1993). A practical method
for calculating largest Lyapunov exponents from small data sets.
Physica D: Nonlinear Phenomena, 65(1-2), 117-134.</p></li>
<li><p>Eckmann, J. P., Kamphorst, S. O., Ruelle, D., &amp; Ciliberto, S. (1986). Liapunov
exponents from time series. Physical Review A, 34(6), 4971.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-rqa">
<h3><em>complexity_rqa()</em><a class="headerlink" href="#complexity-rqa" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_rqa">
<span class="sig-name descname"><span class="pre">complexity_rqa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_linelength</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'python'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_rqa" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Recurrence Quantification Analysis (RQA)</strong></p>
<p>A <a class="reference internal" href="#neurokit2.complexity.recurrence_matrix" title="neurokit2.complexity.recurrence_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">recurrence</span> <span class="pre">plot</span></code></a> is based on a time-delay embedding representation
of a signal and is a 2D depiction of when a system revisits a state that is has been in the
past.</p>
<p>Recurrence quantification analysis (RQA) is a method of complexity analysis
for the investigation of dynamical systems. It quantifies the number and duration
of recurrences of a dynamical system presented by its phase space trajectory.</p>
<p>Features include:</p>
<ul class="simple">
<li><p><strong>Recurrence rate (RR)</strong>: Proportion of points that are labelled as recurrences. Depends on
the radius <em>r</em>.</p></li>
<li><p><strong>Determinism (DET)</strong>: Proportion of recurrence points which form diagonal lines. Indicates
autocorrelation.</p></li>
<li><p><strong>Divergence (DIV)</strong>: The inverse of the longest diagonal line length (<em>LMax</em>).</p></li>
<li><p><strong>Laminarity (LAM)</strong>: Proportion of recurrence points which form vertical lines. Indicates the
amount of laminar phases (intermittency).</p></li>
<li><p><strong>Trapping Time (TT)</strong>: Average length of vertical black lines.</p></li>
<li><p><strong>L</strong>: Average length of diagonal black lines. Average duration that a system is staying in
the same state.</p></li>
<li><p><strong>LEn</strong>: Entropy diagonal lines.</p></li>
<li><p><strong>VMax</strong>: Longest vertical line length.</p></li>
<li><p><strong>VEn</strong>: Entropy vertical lines.</p></li>
<li><p><strong>W</strong>: Average white vertical line length.</p></li>
<li><p><strong>WMax</strong>: Longest white vertical line length.</p></li>
<li><p><strong>WEn</strong>: Entropy white vertical lines.</p></li>
<li><p>Ratio determinism / recurrence rate</p></li>
<li><p>Ratio laminarity / determinism</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More feature exist for RQA, such as the <a class="reference external" href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/rqa/quantification/#RecurrenceAnalysis.trend">trend</a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (similarity threshold, often denoted as ‘r’). The radius used for detecting
neighbours. A rule of thumb is to set r so that the percentage of points classified as
recurrences (<code class="docutils literal notranslate"><span class="pre">info['RecurrenceRate']</span></code>) is about 2-5%.</p></li>
<li><p><strong>min_linelength</strong> (<em>int</em>) – Minimum length of diagonal and vertical lines. Default to 2.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Can be <code class="docutils literal notranslate"><span class="pre">&quot;pyrqa&quot;</span></code> to use the <em>PyRQA</em> package (requires to install it first).</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualise recurrence matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>rqa</strong> (<em>DataFrame</em>) – The RQA results.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – A dictionary containing additional information regarding the parameters used to compute RQA.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"># RQA</span>
<span class="gp">In [3]: </span><span class="n">results</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_rqa</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_rqa1.png"><img alt="savefig/p_complexity_rqa1.png" src="savefig/p_complexity_rqa1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">results</span>
<span class="gh">Out[4]: </span><span class="go"></span>
<span class="go">   RecurrenceRate  Determinism  ...  WMax      WEn</span>
<span class="go">0        0.070398     0.660698  ...   485  3.70312</span>

<span class="go">[1 rows x 14 columns]</span>

<span class="go"># Compare to PyRQA</span>
<span class="go"># results1, info = nk.complexity_rqa(signal, tolerance=1, show=True, method = &quot;pyrqa&quot;)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rawald, T., Sips, M., Marwan, N., &amp; Dransch, D. (2014). Fast computation of recurrences in
long time series. In Translational Recurrences (pp. 17-29). Springer, Cham.</p></li>
</ul>
</dd></dl>

</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">#</a></h2>
<section id="fractal-mandelbrot">
<h3><em>fractal_mandelbrot()</em><a class="headerlink" href="#fractal-mandelbrot" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.fractal_mandelbrot">
<span class="sig-name descname"><span class="pre">fractal_mandelbrot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">real_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-</span> <span class="pre">2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imaginary_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-</span> <span class="pre">2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buddha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.fractal_mandelbrot" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Mandelbrot (or a Buddhabrot) Fractal</strong></p>
<p>Vectorized function to efficiently generate an array containing values corresponding to a
Mandelbrot fractal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – The size in pixels (corresponding to the width of the figure).</p></li>
<li><p><strong>real_range</strong> (<em>tuple</em>) – The mandelbrot set is defined within the -2, 2 complex space (the real being the x-axis and
the imaginary the y-axis). Adjusting these ranges can be used to pan, zoom and crop the
figure.</p></li>
<li><p><strong>imaginary_range</strong> (<em>tuple</em>) – The mandelbrot set is defined within the -2, 2 complex space (the real being the x-axis and
the imaginary the y-axis). Adjusting these ranges can be used to pan, zoom and crop the
figure.</p></li>
<li><p><strong>iterations</strong> (<em>int</em>) – Number of iterations.</p></li>
<li><p><strong>threshold</strong> (<em>int</em>) – The threshold used, increasing it will increase the sharpness (not used for buddhabrots).</p></li>
<li><p><strong>buddha</strong> (<em>bool</em>) – Whether to return a buddhabrot.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualize the fractal.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>ndarray</em> – Array of values.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Create the Mandelbrot fractal</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">m</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">(</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_mandelbrot1.png"><img alt="savefig/p_fractal_mandelbrot1.png" src="savefig/p_fractal_mandelbrot1.png" /></a>
<p>Zoom at the Seahorse Valley</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [3]: </span><span class="n">m</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">(</span><span class="n">real_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.76</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.74</span><span class="p">),</span> <span class="n">imaginary_range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">),</span>
<span class="gp">   ...: </span>                          <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">   ...: </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_mandelbrot2.png"><img alt="savefig/p_fractal_mandelbrot2.png" src="savefig/p_fractal_mandelbrot2.png" /></a>
<p>Draw manually</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="gp">In [5]: </span><span class="n">m</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">(</span><span class="n">real_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span> <span class="n">imaginary_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">))</span>

<span class="gp">In [6]: </span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">)</span>
<span class="gh">Out[6]: </span><span class="go">&lt;matplotlib.image.AxesImage at 0x7f43e9f91630&gt;</span>

<span class="gp">In [7]: </span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="gh">Out[7]: </span><span class="go">(-0.5, 908.5, 999.5, -0.5)</span>

<span class="gp">In [8]: </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_mandelbrot3.png"><img alt="savefig/p_fractal_mandelbrot3.png" src="savefig/p_fractal_mandelbrot3.png" /></a>
<p>Generate a Buddhabrot fractal</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">b</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">real_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span> <span class="n">imaginary_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">),</span>
<span class="gp">   ...: </span>                          <span class="n">buddha</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="gp">   ...: </span>

<span class="gp">In [10]: </span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="gh">Out[10]: </span><span class="go">&lt;matplotlib.image.AxesImage at 0x7f43e9120250&gt;</span>

<span class="gp">In [11]: </span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="gh">Out[11]: </span><span class="go">(-0.5, 1363.5, 1499.5, -0.5)</span>

<span class="gp">In [12]: </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_mandelbrot4.png"><img alt="savefig/p_fractal_mandelbrot4.png" src="savefig/p_fractal_mandelbrot4.png" /></a>
<p>Mixed MandelBuddha</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [13]: </span><span class="n">m</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">()</span>

<span class="gp">In [14]: </span><span class="n">b</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">fractal_mandelbrot</span><span class="p">(</span><span class="n">buddha</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">mixed</span> <span class="o">=</span> <span class="n">m</span> <span class="o">-</span> <span class="n">b</span>

<span class="gp">In [16]: </span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mixed</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="gh">Out[16]: </span><span class="go">&lt;matplotlib.image.AxesImage at 0x7f43e633e110&gt;</span>

<span class="gp">In [17]: </span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="gh">Out[17]: </span><span class="go">(-0.5, 999.5, 999.5, -0.5)</span>

<span class="gp">In [18]: </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_fractal_mandelbrot5.png"><img alt="savefig/p_fractal_mandelbrot5.png" src="savefig/p_fractal_mandelbrot5.png" /></a>
</dd></dl>

</section>
<section id="complexity-simulate">
<h3><em>complexity_simulate()</em><a class="headerlink" href="#complexity-simulate" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_simulate">
<span class="sig-name descname"><span class="pre">complexity_simulate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">duration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ornstein'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hurst_exponent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_simulate" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Simulate chaotic time series</strong></p>
<p>This function generates a chaotic signal using different algorithms and complex systems.</p>
<ul class="simple">
<li><p><strong>Mackey-Glass:</strong> Generates time series using the discrete approximation of the
Mackey-Glass delay differential equation described by Grassberger &amp; Procaccia (1983).</p></li>
<li><p><strong>Ornstein-Uhlenbeck</strong></p></li>
<li><p><strong>Lorenz</strong></p></li>
<li><p><strong>Random walk</strong></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>duration</strong> (<em>int</em>) – Desired length of duration (s).</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – The desired sampling rate (in Hz, i.e., samples/second).</p></li>
<li><p><strong>duration</strong> (<em>int</em>) – The desired length in samples.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – The method. can be <code class="docutils literal notranslate"><span class="pre">&quot;hurst&quot;</span></code> for a (fractional) Ornstein-Uhlenbeck process, <code class="docutils literal notranslate"><span class="pre">&quot;lorenz&quot;</span></code>
for the first dimension of a Lorenz system, <code class="docutils literal notranslate"><span class="pre">&quot;mackeyglass&quot;</span></code> to use the Mackey-Glass
equation, or <code class="docutils literal notranslate"><span class="pre">random</span></code> to generate a random-walk.</p></li>
<li><p><strong>hurst_exponent</strong> (<em>float</em>) – Defaults to 0.5.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>array</em> – Simulated complexity time series.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p><strong>Lorenz System</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lorenz&quot;</span><span class="p">)</span>

<span class="gp">In [3]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate1.png"><img alt="savefig/p_complexity_simulate1.png" src="savefig/p_complexity_simulate1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">5</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="gh">Out[4]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate2.png"><img alt="savefig/p_complexity_simulate2.png" src="savefig/p_complexity_simulate2.png" /></a>
<p><strong>Ornstein System</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ornstein&quot;</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate3.png"><img alt="savefig/p_complexity_simulate3.png" src="savefig/p_complexity_simulate3.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [7]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">100</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="gh">Out[7]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate4.png"><img alt="savefig/p_complexity_simulate4.png" src="savefig/p_complexity_simulate4.png" /></a>
<p><strong>Mackey-Glass System</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [8]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;mackeyglass&quot;</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;green&quot;</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate5.png"><img alt="savefig/p_complexity_simulate5.png" src="savefig/p_complexity_simulate5.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [10]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">25</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="gh">Out[10]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate6.png"><img alt="savefig/p_complexity_simulate6.png" src="savefig/p_complexity_simulate6.png" /></a>
<p><strong>Random walk</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;randomwalk&quot;</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">nk</span><span class="o">.</span><span class="n">signal_plot</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;orange&quot;</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate7.png"><img alt="savefig/p_complexity_simulate7.png" src="savefig/p_complexity_simulate7.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [13]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">100</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="gh">Out[13]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_simulate8.png"><img alt="savefig/p_complexity_simulate8.png" src="savefig/p_complexity_simulate8.png" /></a>
</dd></dl>

</section>
<section id="complexity-attractor">
<h3><em>complexity_attractor()</em><a class="headerlink" href="#complexity-attractor" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_attractor">
<span class="sig-name descname"><span class="pre">complexity_attractor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedded</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lorenz'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'time'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'last_dim'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shadows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linewidth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_attractor" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Attractor Graph</strong></p>
<p>Create an attractor graph from an <code class="xref py py-func docutils literal notranslate"><span class="pre">embedded</span></code> time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedded</strong> (<em>Union[str, np.ndarray]</em>) – Output of <code class="docutils literal notranslate"><span class="pre">complexity_embedding()</span></code>. Can also be a string, such as <code class="docutils literal notranslate"><span class="pre">&quot;lorenz&quot;</span></code> (Lorenz
attractor) or <code class="docutils literal notranslate"><span class="pre">&quot;rossler&quot;</span></code> (Rössler attractor).</p></li>
<li><p><strong>alpha</strong> (<em>Union[str, float]</em>) – Transparency of the lines. If <code class="docutils literal notranslate"><span class="pre">&quot;time&quot;</span></code>, the lines will be transparent as a function of
time (slow).</p></li>
<li><p><strong>color</strong> (<em>str</em>) – Color of the plot. If <code class="docutils literal notranslate"><span class="pre">&quot;last_dim&quot;</span></code>, the last dimension (max 4th) of the embedded data
will be used when the dimensions are higher than 2. Useful to visualize the depth (for
3-dimensions embedding), or the fourth dimension, but it is slow.</p></li>
<li><p><strong>shadows</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, 2D projections will be added to the sides of the 3D attractor.</p></li>
<li><p><strong>linewidth</strong> (<em>float</em>) – Set the line width in points.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments are passed to the color palette (e.g., <code class="docutils literal notranslate"><span class="pre">name=&quot;plasma&quot;</span></code>), or
to the Lorenz system simulator, such as <code class="docutils literal notranslate"><span class="pre">duration</span></code> (default = 100), <code class="docutils literal notranslate"><span class="pre">sampling_rate</span></code>
(default = 10), <code class="docutils literal notranslate"><span class="pre">sigma</span></code> (default = 10), <code class="docutils literal notranslate"><span class="pre">beta</span></code> (default = 8/3), <code class="docutils literal notranslate"><span class="pre">rho</span></code> (default = 28).</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embeddding</span></code></p>
</div>
<p class="rubric">Examples</p>
<p><strong>Lorenz attractors</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">fig</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;last_dim&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor1.png"><img alt="savefig/p_complexity_attractor1.png" src="savefig/p_complexity_attractor1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Fast result (fixed alpha and color)</span>
<span class="gp">In [3]: </span><span class="n">fig</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor2.png"><img alt="savefig/p_complexity_attractor2.png" src="savefig/p_complexity_attractor2.png" /></a>
<p><strong>Rössler attractors</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="s2">&quot;rossler&quot;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="gh">Out[4]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor3.png"><img alt="savefig/p_complexity_attractor3.png" src="savefig/p_complexity_attractor3.png" /></a>
<p><strong>2D Attractors using a signal</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Simulate Signal</span>
<span class="gp">In [5]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="go"># 2D Attractor</span>
<span class="gp">In [6]: </span><span class="n">embedded</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dimension</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="go"># Fast (fixed alpha and color)</span>
<span class="gp">In [7]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="gh">Out[7]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor4.png"><img alt="savefig/p_complexity_attractor4.png" src="savefig/p_complexity_attractor4.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Slow</span>
<span class="gp">In [8]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;last_dim&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>
<span class="gh">Out[8]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor5.png"><img alt="savefig/p_complexity_attractor5.png" src="savefig/p_complexity_attractor5.png" /></a>
<p><strong>3D Attractors using a signal</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># 3D Attractor</span>
<span class="gp">In [9]: </span><span class="n">embedded</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_embedding</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dimension</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"># Fast (fixed alpha and color)</span>
<span class="gp">In [10]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="gh">Out[10]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor6.png"><img alt="savefig/p_complexity_attractor6.png" src="savefig/p_complexity_attractor6.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Slow</span>
<span class="gp">In [11]: </span><span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;last_dim&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>
<span class="gh">Out[11]: </span><span class="go">&lt;Figure size 640x480 with 1 Axes&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_attractor7.png"><img alt="savefig/p_complexity_attractor7.png" src="savefig/p_complexity_attractor7.png" /></a>
<p><strong>Animated Rotation</strong></p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [12]: </span><span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="gp">In [13]: </span><span class="kn">import</span> <span class="nn">IPython</span>

<span class="gp">In [14]: </span><span class="n">fig</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_attractor</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shadows</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">get_axes</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="gp">In [16]: </span><span class="k">def</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">angle</span><span class="p">):</span>
<span class="gp">   ....: </span>    <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">azim</span><span class="o">=</span><span class="n">angle</span><span class="p">)</span>
<span class="gp">   ....: </span><span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">rotate</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">361</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">   ....: </span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">())</span>
<span class="gp">   ....: </span>
<span class="gh">Out[16]: </span><span class="go">&lt;IPython.core.display.HTML object&gt;</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="complexity-symbolize">
<h3><em>complexity_symbolize</em><a class="headerlink" href="#complexity-symbolize" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_symbolize">
<span class="sig-name descname"><span class="pre">complexity_symbolize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_symbolize" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Signal Symbolization and Discretization</strong></p>
<p>Many complexity indices are made to assess the recurrence and predictability of discrete -
symbolic - states. As such, continuous signals must be transformed into such discrete sequence.</p>
<p>For instance, one of the easiest way is to split the signal values into two categories, above
and below the mean, resulting in a sequence of <em>A</em> and <em>B</em>. More complex methods have been
developped to that end.</p>
<ul class="simple">
<li><p><strong>Method ‘A’</strong> binarizes the signal by higher vs. lower values as compated to the signal’s
mean.</p></li>
<li><p><strong>Method ‘B’</strong> uses values that are within the mean +/- 1 SD band vs. values that are outside
this band.</p></li>
<li><p><strong>Method ‘C’</strong> computes the difference between consecutive samples and binarizes depending on
their sign.</p></li>
<li><p><strong>Method ‘D’</strong> forms separates consecutive samples that exceed 1 signal’s SD from the others
smaller changes.</p></li>
<li><p><strong>Method ‘r’</strong> is based on the concept of <a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">*tolerance*</span></code></a>, and
will separate consecutive samples that exceed a given tolerance threshold, by default
<span class="math notranslate nohighlight">\(0.2 * SD\)</span>. See <a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> for more details.</p></li>
<li><p><strong>Binning</strong>: If an integer <em>n</em> is passed, will bin the signal into <em>n</em> equal-width bins.
Requires to specify <em>c</em>.</p></li>
<li><p><strong>MEP</strong>: Maximum Entropy Partitioning. Requires to specify <em>c</em>.</p></li>
<li><p><strong>NCDF</strong>: Please help us to improve the documentation here. Requires to specify <em>c</em>.</p></li>
<li><p><strong>Linear</strong>: Please help us to improve the documentation here. Requires to specify <em>c</em>.</p></li>
<li><p><strong>Uniform</strong>: Please help us to improve the documentation here. Requires to specify <em>c</em>.</p></li>
<li><p><strong>kmeans</strong>: k-means clustering. Requires to specify <em>c</em>.</p></li>
</ul>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul>
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>method</strong> (<em>str or int</em>) – Method of symbolization. Can be one of <code class="docutils literal notranslate"><span class="pre">&quot;A&quot;</span></code> (default), <code class="docutils literal notranslate"><span class="pre">&quot;B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;C&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;D&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;r&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;Binning&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;MEP&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;NCDF&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;uniform&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;kmeans&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;equal&quot;</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to skip the process (for instance, in cases when the binarization
has already been done before).</p>
<p>See <a class="reference internal" href="#neurokit2.complexity.complexity_symbolize" title="neurokit2.complexity.complexity_symbolize"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_symbolize()</span></code></a> for details.</p>
</li>
<li><p><strong>c</strong> (<em>int</em>) – Number of symbols <em>c</em>, used in some algorithms.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Plot the reconstructed attractor. See <a class="reference internal" href="#neurokit2.complexity.complexity_attractor" title="neurokit2.complexity.complexity_attractor"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_attractor()</span></code></a> for details.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments to be passed to <a class="reference internal" href="#neurokit2.complexity.complexity_attractor" title="neurokit2.complexity.complexity_attractor"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_attractor()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>array</em> – A symbolic sequence made of discrete states (e.g., 0 and 1).</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.entropy_shannon" title="neurokit2.complexity.entropy_shannon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_shannon</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">entropy_cumulative_residual</span></code>, <a class="reference internal" href="#neurokit2.complexity.fractal_petrosian" title="neurokit2.complexity.fractal_petrosian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fractal_petrosian</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>

<span class="go"># Method &quot;A&quot; is equivalent to &quot;mean&quot;</span>
<span class="gp">In [3]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize1.png"><img alt="savefig/p_complexity_symbolize1.png" src="savefig/p_complexity_symbolize1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize2.png"><img alt="savefig/p_complexity_symbolize2.png" src="savefig/p_complexity_symbolize2.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [5]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize3.png"><img alt="savefig/p_complexity_symbolize3.png" src="savefig/p_complexity_symbolize3.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize4.png"><img alt="savefig/p_complexity_symbolize4.png" src="savefig/p_complexity_symbolize4.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [8]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize5.png"><img alt="savefig/p_complexity_symbolize5.png" src="savefig/p_complexity_symbolize5.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [9]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;binning&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize6.png"><img alt="savefig/p_complexity_symbolize6.png" src="savefig/p_complexity_symbolize6.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [10]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;MEP&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize7.png"><img alt="savefig/p_complexity_symbolize7.png" src="savefig/p_complexity_symbolize7.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;NCDF&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize8.png"><img alt="savefig/p_complexity_symbolize8.png" src="savefig/p_complexity_symbolize8.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [12]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize9.png"><img alt="savefig/p_complexity_symbolize9.png" src="savefig/p_complexity_symbolize9.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [13]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;equal&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize10.png"><img alt="savefig/p_complexity_symbolize10.png" src="savefig/p_complexity_symbolize10.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [14]: </span><span class="n">symbolic</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_symbolize</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_symbolize11.png"><img alt="savefig/p_complexity_symbolize11.png" src="savefig/p_complexity_symbolize11.png" /></a>
</dd></dl>

</section>
<section id="complexity-coarsegraining">
<h3><em>complexity_coarsegraining()</em><a class="headerlink" href="#complexity-coarsegraining" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_coarsegraining">
<span class="sig-name descname"><span class="pre">complexity_coarsegraining</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nonoverlapping'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_coarsegraining" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Coarse-graining of a signal</strong></p>
<p>The goal of coarse-graining is to represent the signal at a different “scale”. The
coarse-grained time series for a scale factor Tau (<span class="math notranslate nohighlight">\(\tau\)</span>) are obtained by averaging
non-overlapping windows of size Tau. In most of the complexity metrics, multiple coarse-grained
segments are constructed for a given signal, to represent the signal at different scales (hence
the “multiscale” adjective).</p>
<figure class="align-default">
<a class="reference external image-reference" href="https://doi.org/10.1016/j.physleta.2014.03.034"><img alt="Figure from Wu et al. (2013)." src="../_images/wu2013a.png" /></a>
</figure>
<p>This coarse-graining procedure is similar to moving averaging and the decimation of the original
time series. The length of each coarse-grained time series is N/Tau. For scale = 1, the
coarse-grained time series is simply the original time series itself.</p>
<p>The coarse graining procedure (used for instance in MSE) is considered a shortcoming that
decreases the entropy rate artificially (Nikulin, 2004). One of the core issue is that the
length of coarse-grained signals becomes smaller as the scale increases.</p>
<p>To address this issue of length, several methods have been proposed, such as <strong>adaptive
resampling</strong> (Liu et al. 2012), <strong>moving average</strong> (Wu et al. 2013), or <strong>timeshift</strong>
(Wu et al. 2013).</p>
<ul class="simple">
<li><p><strong>Non-overlapping</strong> (default): The coarse-grained time series are constructed by averaging
non-overlapping windows of given size.</p></li>
<li><p><strong>Interpolate</strong>: Interpolates (i.e., resamples) the coarse-grained time series to match the
original signal length (currently using a monotonic cubic method, but let us know if you have
any opinion on that).</p></li>
<li><p><strong>Moving average</strong>: The coarse-grained time series via a moving average.</p></li>
<li><p><strong>Time-shift</strong>: For each scale, a <em>k</em> number of coarse-grained vectors are constructed (see
<strong>Figure</strong> below). Somewhat similar to moving-average, with the difference that the time lag
creates new vectors.</p></li>
</ul>
<figure class="align-default">
<a class="reference external image-reference" href="https://doi.org/10.1016/j.physleta.2014.03.034"><img alt="Figure from Wu et al. (2013)." src="../_images/wu2013b.png" /></a>
</figure>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – The size of the windows that the signal is divided into. Also referred to as Tau
<span class="math notranslate nohighlight">\(\tau\)</span>, it represents the scale factor and corresponds to
the amount of coarsegraining.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Can be <code class="docutils literal notranslate"><span class="pre">&quot;nonoverlapping&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;rolling&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;interpolate&quot;</span></code>, or <code class="docutils literal notranslate"><span class="pre">timeshift</span></code>.</p></li>
<li><p><strong>force</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will include all the samples (even if the last segment is too short).</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will show the coarse-grained signal.</p></li>
<li><p><strong>**kwargs</strong> – Other arguments (not used currently).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>array</em> – The coarse-grained signal.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<p><strong>Simple examples</strong>
.. ipython:: python</p>
<blockquote>
<div><p>import neurokit2 as nk</p>
<p>signal = [0, 2, 4, 6, 8, 10]
nk.complexity_coarsegraining(signal, scale=2)</p>
<p>signal = [0, 1, 2, 0, 1]
nk.complexity_coarsegraining(signal, scale=3)
# Forcing uses all the samples even if the last segment is too short
nk.complexity_coarsegraining(signal, scale=3, force=True)</p>
<p>nk.complexity_coarsegraining(signal=range(10), method=”interpolate”)
nk.complexity_coarsegraining(signal=range(10), method=”rolling”)</p>
</div></blockquote>
<p><strong>Simulated signal</strong>
.. ipython:: python</p>
<blockquote>
<div><p>signal = nk.signal_simulate(duration=2, frequency=[5, 20])</p>
<p>&#64;savefig p_complexity_coarsegraining1.png scale=100%
coarsegrained = nk.complexity_coarsegraining(signal, scale=40, show=True)
&#64;suppress
plt.close()</p>
</div></blockquote>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="n">coarsegrained</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_coarsegraining</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;interpolate&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_coarsegraining2.png"><img alt="savefig/p_complexity_coarsegraining2.png" src="savefig/p_complexity_coarsegraining2.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [2]: </span><span class="n">coarsegrained</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_coarsegraining</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;rolling&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_coarsegraining3.png"><img alt="savefig/p_complexity_coarsegraining3.png" src="savefig/p_complexity_coarsegraining3.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [3]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>

<span class="gp">In [4]: </span><span class="n">coarsegrained</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_coarsegraining</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;timeshift&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_complexity_coarsegraining4.png"><img alt="savefig/p_complexity_coarsegraining4.png" src="savefig/p_complexity_coarsegraining4.png" /></a>
<p><strong>Benchmarking</strong>
.. ipython:: python</p>
<blockquote>
<div><p>signal = nk.signal_simulate(duration=10, frequency=5)
scale = 2
x_pd = pd.Series(signal).rolling(window=scale).mean().values[scale-1::scale]
x_nk = nk.complexity_coarsegraining(signal, scale=scale)
np.allclose(x_pd - x_nk, 0)</p>
<p>%timeit x_pd = pd.Series(signal).rolling(window=scale).mean().values[scale-1::scale]
%timeit x_nk = nk.complexity_coarsegraining(signal, scale=scale)</p>
<p>signal = nk.signal_simulate(duration=30, frequency=5)
scale = 3</p>
<p>x_pd = pd.Series(signal).rolling(window=scale).mean().values[scale-1::]
x_nk = nk.complexity_coarsegraining(signal, scale=scale, rolling=True)
np.allclose(x_pd - x_nk[1:-1], 0)</p>
<p>%timeit pd.Series(signal).rolling(window=scale).mean().values[scale-1::]
%timeit nk.complexity_coarsegraining(signal, scale=scale, rolling=True)</p>
</div></blockquote>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Su, C., Liang, Z., Li, X., Li, D., Li, Y., &amp; Ursino, M. (2016). A comparison of multiscale
permutation entropy measures in on-line depth of anesthesia monitoring. PLoS One, 11(10),
e0164104.</p></li>
<li><p>Nikulin, V. V., &amp; Brismar, T. (2004). Comment on “Multiscale entropy analysis of complex
physiologic time series”” Physical review letters, 92(8), 089803.</p></li>
<li><p>Liu, Q., Wei, Q., Fan, S. Z., Lu, C. W., Lin, T. Y., Abbod, M. F., &amp; Shieh, J. S. (2012).
Adaptive computation of multiscale entropy and its application in EEG signals for monitoring
depth of anesthesia during surgery. Entropy, 14(6), 978-992.</p></li>
<li><p>Wu, S. D., Wu, C. W., Lee, K. Y., &amp; Lin, S. G. (2013). Modified multiscale entropy for
short-term time series analysis. Physica A: Statistical Mechanics and its Applications, 392
(23), 5865-5873.</p></li>
<li><p>Wu, S. D., Wu, C. W., Lin, S. G., Wang, C. C., &amp; Lee, K. Y. (2013). Time series analysis
using composite multiscale entropy. Entropy, 15(3), 1069-1084.</p></li>
</ul>
</dd></dl>

</section>
<section id="complexity-ordinalpatterns">
<h3><em>complexity_ordinalpatterns()</em><a class="headerlink" href="#complexity-ordinalpatterns" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.complexity_ordinalpatterns">
<span class="sig-name descname"><span class="pre">complexity_ordinalpatterns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'quicksort'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.complexity_ordinalpatterns" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Find Ordinal Patterns for Permutation Procedures</strong></p>
<p>The seminal work by Bandt and Pompe (2002) introduced a symbolization approach to obtain a
sequence of ordinal patterns (permutations) from continuous data. It is used in
<a class="reference internal" href="#neurokit2.complexity.entropy_permutation" title="neurokit2.complexity.entropy_permutation"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation</span> <span class="pre">entropy</span></code></a> and its different variants.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.array, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>algorithm</strong> (<em>str</em>) – Can be <code class="docutils literal notranslate"><span class="pre">&quot;quicksort&quot;</span></code> (default) or <code class="docutils literal notranslate"><span class="pre">&quot;bubblesort&quot;</span></code> (used in Bubble Entropy).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>array</em> – Ordinal patterns.</p></li>
<li><p><em>vector</em> – Frequencies of each ordinal pattern.</p></li>
<li><p><em>dict</em> – A dictionary containing additional elements.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Example given by Bandt and Pompe (2002):</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">patterns</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_ordinalpatterns</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">patterns</span>
<span class="gh">Out[4]: </span><span class="go"></span>
<span class="go">array([[0, 1, 2],</span>
<span class="go">       [1, 0, 2],</span>
<span class="go">       [2, 0, 1]])</span>

<span class="gp">In [5]: </span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;Frequencies&quot;</span><span class="p">]</span>
<span class="gh">Out[5]: </span><span class="go">array([0.4, 0.2, 0.4])</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">signal</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="gp">In [7]: </span><span class="n">patterns</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_ordinalpatterns</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;bubblesort&quot;</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;Frequencies&quot;</span><span class="p">]</span>
<span class="gh">Out[8]: </span><span class="go">array([0.36363636, 0.09090909, 0.18181818, 0.36363636])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Bandt, C., &amp; Pompe, B. (2002). Permutation entropy: a natural complexity measure for time
series. Physical review letters, 88(17), 174102.</p></li>
<li><p>Manis, G., Aktaruzzaman, M. D., &amp; Sassi, R. (2017). Bubble entropy: An entropy almost free of
parameters. IEEE Transactions on Biomedical Engineering, 64(11), 2711-2718.</p></li>
</ul>
</dd></dl>

</section>
<section id="recurrence-matrix">
<h3><em>recurrence_matrix()</em><a class="headerlink" href="#recurrence-matrix" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.recurrence_matrix">
<span class="sig-name descname"><span class="pre">recurrence_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.recurrence_matrix" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Recurrence Matrix</strong></p>
<p>Fast Python implementation of recurrence matrix (tested against pyRQA). Returns a tuple
with the recurrence matrix (made of 0s and 1s) and the distance matrix (the non-binarized
version of the former).</p>
<p>It is used in <a class="reference internal" href="#neurokit2.complexity.complexity_rqa" title="neurokit2.complexity.complexity_rqa"><code class="xref py py-func docutils literal notranslate"><span class="pre">Recurrence</span> <span class="pre">Quantification</span> <span class="pre">Analysis</span> <span class="pre">(RQA)</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> (<em>Union[list, np.ndarray, pd.Series]</em>) – The signal (i.e., a time series) in the form of a vector of values.</p></li>
<li><p><strong>delay</strong> (<em>int</em>) – Time delay (often denoted <em>Tau</em> <span class="math notranslate nohighlight">\(\tau\)</span>, sometimes referred to as <em>lag</em>) in samples.
See <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_delay()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – Embedding Dimension (<em>m</em>, sometimes referred to as <em>d</em> or <em>order</em>). See
<a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_dimension()</span></code></a> to estimate the optimal value for this parameter.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Tolerance (often denoted as <em>r</em>), distance to consider two data points as similar. If
<code class="docutils literal notranslate"><span class="pre">&quot;sd&quot;</span></code> (default), will be set to <span class="math notranslate nohighlight">\(0.2 * SD_{signal}\)</span>. See
<a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-func docutils literal notranslate"><span class="pre">complexity_tolerance()</span></code></a> to estimate the optimal value for this parameter. A rule of
thumb is to set <em>r</em> so that the percentage of points classified as recurrences is about
2-5%.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Visualise recurrence matrix.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_embedding</span></code>, <a class="reference internal" href="#neurokit2.complexity.complexity_delay" title="neurokit2.complexity.complexity_delay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_delay</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_dimension" title="neurokit2.complexity.complexity_dimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_dimension</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_tolerance" title="neurokit2.complexity.complexity_tolerance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_tolerance</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.complexity_rqa" title="neurokit2.complexity.complexity_rqa"><code class="xref py py-obj docutils literal notranslate"><span class="pre">complexity_rqa</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>np.ndarray</em> – The recurrence matrix.</p></li>
<li><p><em>np.ndarray</em> – The distance matrix.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">signal</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">signal_simulate</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="go"># Default r</span>
<span class="gp">In [3]: </span><span class="n">rc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">recurrence_matrix</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_recurrence_matrix1.png"><img alt="savefig/p_recurrence_matrix1.png" src="savefig/p_recurrence_matrix1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Larger radius</span>
<span class="gp">In [4]: </span><span class="n">rc</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">recurrence_matrix</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_recurrence_matrix2.png"><img alt="savefig/p_recurrence_matrix2.png" src="savefig/p_recurrence_matrix2.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="go"># Optimization of tolerance via recurrence matrix</span>
<span class="gp">In [5]: </span><span class="n">tol</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">complexity_tolerance</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;recurrence&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_recurrence_matrix3.png"><img alt="savefig/p_recurrence_matrix3.png" src="savefig/p_recurrence_matrix3.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [6]: </span><span class="n">rc</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">recurrence_matrix</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_recurrence_matrix4.png"><img alt="savefig/p_recurrence_matrix4.png" src="savefig/p_recurrence_matrix4.png" /></a>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Rawald, T., Sips, M., Marwan, N., &amp; Dransch, D. (2014). Fast computation of recurrences
in long time series. In Translational Recurrences (pp. 17-29). Springer, Cham.</p></li>
<li><p>Dabiré, H., Mestivier, D., Jarnet, J., Safar, M. E., &amp; Chau, N. P. (1998). Quantification of
sympathetic and parasympathetic tones by nonlinear indexes in normotensive rats. American
Journal of Physiology-Heart and Circulatory Physiology, 275(4), H1290-H1297.</p></li>
</ul>
</dd></dl>

</section>
</section>
<section id="markov-chains">
<h2>Markov Chains<a class="headerlink" href="#markov-chains" title="Permalink to this headline">#</a></h2>
<section id="transition-matrix">
<h3><em>transition_matrix()</em><a class="headerlink" href="#transition-matrix" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.transition_matrix">
<span class="sig-name descname"><span class="pre">transition_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.transition_matrix" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Transition Matrix</strong></p>
<p>A Transition Matrix (also known as a stochastic matrix or a Markov matrix) is the first step to
describe a sequence of states, also known as <strong>discrete Markov chains</strong>. Each of its entries is
a probability of transitioning from one state to the other.</p>
<p>Computes the observed transition matrix and performs a
Chi-square test against the expected transition matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> (<em>Union[list, np.array, pd.Series]</em>) – A list of discrete states.</p></li>
<li><p><strong>show</strong> (<em>bool</em>) – Displays the transition matrix heatmap.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.markov_simulate" title="neurokit2.complexity.markov_simulate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markov_simulate</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.markov_test_random" title="neurokit2.complexity.markov_test_random"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markov_test_random</span></code></a>, <a class="reference internal" href="#neurokit2.complexity.markov_test_symmetry" title="neurokit2.complexity.markov_test_symmetry"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markov_test_symmetry</span></code></a></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>pd.DataFrame</em> – The empirical (observed) transition matrix.</p></li>
<li><p><em>dict</em> – A dictionnary containing additional information, such as the Frequency Matrix (<strong>fm</strong>;
accessible via the key <code class="docutils literal notranslate"><span class="pre">&quot;Occurrences&quot;</span></code>), useful for some tests.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">tm</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="savefig/p_transition_matrix1.png"><img alt="savefig/p_transition_matrix1.png" src="savefig/p_transition_matrix1.png" /></a>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [4]: </span><span class="n">tm</span>
<span class="gh">Out[4]: </span><span class="go"></span>
<span class="go">          0         1         2         3</span>
<span class="go">0  0.666667  0.333333  0.000000  0.333333</span>
<span class="go">1  0.500000  0.000000  0.500000  0.000000</span>
<span class="go">2  0.000000  0.333333  0.666667  0.000000</span>
<span class="go">3  0.250000  0.250000  0.250000  0.250000</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="markov-simulate">
<h3><em>markov_simulate()</em><a class="headerlink" href="#markov-simulate" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.markov_simulate">
<span class="sig-name descname"><span class="pre">markov_simulate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.markov_simulate" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Markov Chain Simulation</strong></p>
<p>Given a <a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">transition_matrix()</span></code></a>, this function simulates the corresponding sequence of states
(also known as a discrete Markov chain).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tm</strong> (<em>pd.DataFrame</em>) – A probability matrix obtained from <a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">transition_matrix()</span></code></a>.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – Length of the simulated sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>np.ndarray</em> – Sequence of states.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transition_matrix</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">tm</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">x</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">markov_simulate</span><span class="p">(</span><span class="n">tm</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">x</span>
<span class="gh">Out[5]: </span><span class="go">array([3, 3, 0, 1, 0, 0, 0, 0, 1, 2, 2, 1, 2, 1, 2])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="markov-test-random">
<h3><em>markov_test_random()</em><a class="headerlink" href="#markov-test-random" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.markov_test_random">
<span class="sig-name descname"><span class="pre">markov_test_random</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fm</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.markov_test_random" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Is the Markov process random?</strong></p>
<p>This function computes the expected (theoretical) transition matrix if the order of appearance
of each state was governed only by their overall prevalence, and that a previous state had no
influence on the next state. This “random” matrix is then compered again the observed one, and
a Chi2 test is conducted.</p>
<p>If significant (e.g., <em>p</em>-value &lt; .05), one can reject the hypothesis that observed Markov
process is random, and conclude that past states have an influence on next states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fm</strong> (<em>pd.DataFrame</em>) – A frequency matrix obtained from <a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">transition_matrix()</span></code></a>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>dict</em> – Contains indices of the Chi2 test.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transition_matrix</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">result</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">markov_test_random</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;Occurrences&quot;</span><span class="p">])</span>

<span class="gp">In [5]: </span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;Random_p&quot;</span><span class="p">]</span>
<span class="gh">Out[5]: </span><span class="go">0.8815729751590916</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="markov-test-symmetry">
<h3><em>markov_test_symmetry()</em><a class="headerlink" href="#markov-test-symmetry" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.markov_test_symmetry">
<span class="sig-name descname"><span class="pre">markov_test_symmetry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fm</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.markov_test_symmetry" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Is the Markov process symmetric?</strong></p>
<p>Performs a symmetry test. If significant (e.g., <em>p</em>-value &lt; .05), one can reject the hypothesis
that observed Markov process is symmetric, and conclude that it the transition matrix is
asymmetric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fm</strong> (<em>pd.DataFrame</em>) – A frequency matrix obtained from <a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">transition_matrix()</span></code></a>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>dict</em> – Contains indices of the test.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transition_matrix</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">result</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">markov_test_symmetry</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;Occurrences&quot;</span><span class="p">])</span>

<span class="gp">In [5]: </span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;Symmetry_p&quot;</span><span class="p">]</span>
<span class="gh">Out[5]: </span><span class="go">1.0</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Kullback, S., Kupperman, M., &amp; Ku, H. H. (1962). Tests for contingency tables and Markov
chains. Technometrics, 4(4), 573-608.</p></li>
</ul>
</dd></dl>

</section>
<section id="markov-test-homogeneity">
<h3><em>markov_test_homogeneity()</em><a class="headerlink" href="#markov-test-homogeneity" title="Permalink to this headline">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="neurokit2.complexity.markov_test_homogeneity">
<span class="sig-name descname"><span class="pre">markov_test_homogeneity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neurokit2.complexity.markov_test_homogeneity" title="Permalink to this definition">#</a></dt>
<dd><p><strong>Is the Markov process homogeneous?</strong></p>
<p>Performs a homogeneity test that tests the null hypothesis that the samples are
homogeneous, i.e., from the same - but unspecified - population, against the alternative
hypothesis that at least one pair of samples is from different populations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> (<em>Union[list, np.array, pd.Series]</em>) – A list of discrete states.</p></li>
<li><p><strong>size</strong> (<em>int</em>) – The size of the non-overlapping windows to split the sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>dict</em> – Contains indices of the test.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#neurokit2.complexity.transition_matrix" title="neurokit2.complexity.transition_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transition_matrix</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">neurokit2</span> <span class="k">as</span> <span class="nn">nk</span>

<span class="gp">In [2]: </span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">In [3]: </span><span class="n">result</span> <span class="o">=</span> <span class="n">nk</span><span class="o">.</span><span class="n">markov_test_homogeneity</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [4]: </span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;Homogeneity_p&quot;</span><span class="p">]</span>
<span class="gh">Out[4]: </span><span class="go">0.9999999999999952</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Kullback, S., Kupperman, M., &amp; Ku, H. H. (1962). Tests for contingency tables and Markov
chains. Technometrics, 4(4), 573-608.</p></li>
</ul>
</dd></dl>

</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="functions_ppg.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">PPG</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../studies/index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Studies</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By <a href="https://dominiquemakowski.github.io/">Dominique Makowski</a> and the <a href="https://github.com/neuropsychology/NeuroKit/blob/master/AUTHORS.rst">Team</a><br/>
  
      &copy; Copyright 2020–2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>